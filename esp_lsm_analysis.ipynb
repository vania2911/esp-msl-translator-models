{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vania2911/esp-msl-translator-models/blob/main/esp_lsm_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "0ZVBGXCLpRwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eafa1f75-0cb5-496a-e7ab-ae147eee55fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N-Xrq7oZRoPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078724ed-3154-4845-8306-09f029589aae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "id": "VBM6PVUYRxgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb081293-905c-4a95-9941-817bf48a7701"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "id": "Jr3ccZNpkJSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9ccbe3-a122-4fb5-e668-7e649cc7c5dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blis, thinc, spacy\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.2.0 spacy-3.8.4 thinc-8.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_md\n"
      ],
      "metadata": {
        "id": "eiFdxFtgjg64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f4dfdb-cf58-4a58-f929-677a5e18b810"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.8.0/es_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "y0zR3-PlkZ2F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L84lCyxZLXJq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS0qxe2FLVFP",
        "outputId": "4733dd80-2ab5-478b-b5ff-ce4018aa6a77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "id": "_ZzBkKZYIJ9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2427ce-7746-4646-ec84-b5313d27e397"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-md==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.8.0/es_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "em4ObDb23PZp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk # Install the nltk library\n",
        "import nltk # Import the nltk module\n",
        "\n",
        "nltk.download('wordnet') # Download WordNet if you haven't already\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "QMs5_C9vMbmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d93b31-f009-4843-91cb-ad65bdc43068"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7hxBTdE6JZE",
        "outputId": "cd6cf981-bcea-4d1d-a444-8589f602a2ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.7.1\n",
            "    Uninstalling en-core-web-sm-3.7.1:\n",
            "      Successfully uninstalled en-core-web-sm-3.7.1\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "6KUMHPEg6bkM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nlp = spacy.load(\"es_core_news_sm\")\n",
        "doc = nlp(sentences_esp)\n",
        "print(doc.text)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "metadata": {
        "id": "I2ke4H5ckn-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "835b250d-cb3c-4cf8-e712-cfade3ef5078"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sentences_esp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-94442a1d0cf3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#nlp = spacy.load(\"es_core_news_sm\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_esp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sentences_esp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet') # Download WordNet if you haven't already\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "BTyyqStj3npl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xNVQ0i3EUsoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "cIzxutN63vqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_csv=pd.read_csv(\"/content/drive/MyDrive/doctorado/paper_scientificdata/esp-lsm.csv\")\n",
        "r_csv_new=r_csv[['esp','lsm']]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zDG_jy5lUu8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_csv_new['esp']=r_csv_new['esp'].str.lower()\n",
        "r_csv_new_esp=r_csv_new['esp'].apply(lambda x: nlp(x))\n",
        "r_csv_new_esp"
      ],
      "metadata": {
        "id": "SPktzcJwhJiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listof=[]\n",
        "for doc in r_csv_new_esp:\n",
        "  for token in doc:\n",
        "    tuple1=(token.text,token.pos_,token.tag_,token.dep_,str(spacy.explain(token.dep_)))\n",
        "    listof.append(tuple1)\n",
        "\n",
        "print(listof)\n",
        "df=pd.DataFrame(listof,columns=['text','pos','tag','dep','meaning'])\n",
        "df"
      ],
      "metadata": {
        "id": "INahsojFky0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['pos'].value_counts()\n",
        "y_i=pd.DataFrame(data=y)\n",
        "y_i=y_i.reset_index().drop([7,9, 10, 11, 12,13])\n",
        "y_i"
      ],
      "metadata": {
        "id": "BnJP-dd1unEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng"
      ],
      "metadata": {
        "id": "BqC55IPGstoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['text.usetex'] = True\n",
        "plt.figure(figsize=(15,10))\n",
        "bar_colors=['blue', 'pink', 'orange', 'red', 'purple', 'turquoise', 'yellow', 'lightblue', 'palegreen', 'red', 'salmon', 'royalblue', 'hotpink']\n",
        "bar_legend=['NOUN', 'DET', 'VERB','AUX','ADJ','PRON','ADV','PUNCT']\n",
        "plt.bar(x=y_i['pos'], height=y_i['count'], color=bar_colors)\n",
        "plt.ylabel('Frequency',fontsize=20)\n",
        "plt.xlabel('Part of Speech (POS)',fontsize=24)\n",
        "plt.title('Spanish Sentences', fontsize=24)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.box(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdnahEkkuiJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_csv_new['lsm']=r_csv_new['lsm'].str.lower()\n",
        "r_csv_new_lsm=r_csv_new['lsm'].apply(lambda x: nlp(x))\n",
        "r_csv_new_lsm['len']=r_csv_new_lsm.apply(lambda x: len(x))\n",
        "r_csv_new_lsm.info()"
      ],
      "metadata": {
        "id": "XsvvmM9sxx0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listof=[]\n",
        "for doc in r_csv_new_lsm:\n",
        "  # Check if doc is a spaCy Doc object before iterating through it\n",
        "  if isinstance(doc, spacy.tokens.doc.Doc):\n",
        "    for token in doc:\n",
        "      tuple1=(token.text,token.pos_,token.tag_,token.dep_,str(spacy.explain(token.dep_)))\n",
        "      listof.append(tuple1)\n",
        "\n",
        "print(listof)\n",
        "df_lsm=pd.DataFrame(listof,columns=['text','pos','tag','dep','meaning'])\n",
        "df_lsm"
      ],
      "metadata": {
        "id": "ElfawiEQyN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jCAuX6mh9HCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_lsm=df_lsm['pos'].value_counts()\n",
        "y_lsm=pd.DataFrame(data=y_lsm)\n",
        "#y_lsm=y_lsm.reset_index().drop([7,9,10,11,12,13,14,15])\n",
        "y_lsm"
      ],
      "metadata": {
        "id": "lVBCDUEMyeIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WZDWIOSjwXj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VOUSKx8HwYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "c490Rt9Gz8l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['text.usetex'] = True\n",
        "plt.figure(figsize=(15,10))\n",
        "bar_colors=['blue', 'pink', 'orange', 'red', 'purple', 'turquoise', 'yellow', 'lightblue', 'palegreen', 'red', 'salmon', 'royalblue', 'hotpink']\n",
        "#bar_legend=['NOUN', 'DET', 'VERB','AUX','ADJ','PRON','ADV','PUNCT']\n",
        "plt.bar(x=y_lsm['pos'], height=y_lsm['count'], color=bar_colors)\n",
        "plt.ylabel('Frequency',fontsize=24)\n",
        "plt.xlabel('Part of Speech (POS)',fontsize=24)\n",
        "plt.title('Mexican Sign Language (MSL) Sentences', fontsize=24)\n",
        "plt.box(True)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HPX0JFLKBiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#most common adjectives\n",
        "df_adj=df[df['pos']=='ADV']\n",
        "df_spa_adj_count=df_adj['text'].value_counts()\n",
        "df_spa_adj_count.sort_values(ascending=False)\n",
        "df_spa_adj_count[:10]\n"
      ],
      "metadata": {
        "id": "VkqOWE94zdeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#most common adjectives\n",
        "df_adj=df[df['pos']=='PROPN']\n",
        "#df_spa_adj_count=df_adj['text'].value_counts()\n",
        "#df_spa_adj_count.sort_values(ascending=False)\n",
        "#df_spa_adj_count\n",
        "df_adj"
      ],
      "metadata": {
        "id": "iP7exkkmWrbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=df['text'].value_counts()\n",
        "vocab=pd.Series(vocab)\n",
        "vocab"
      ],
      "metadata": {
        "id": "xTPtjJ_rPv2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_lsm=df_lsm['text'].value_counts()\n",
        "vocab_lsm=pd.Series(vocab_lsm)\n",
        "vocab_lsm"
      ],
      "metadata": {
        "id": "YY4AZJVpqjnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_csv_new['lsm']=r_csv_new['lsm'].str.lower()\n",
        "r_csv_new['len_lsm']=r_csv_new['lsm'].apply(lambda x: len(x.split(\" \")) if isinstance(x,str) else None)\n",
        "r_csv_new['len_esp']=r_csv_new['esp'].apply(lambda x: len(x.split(\" \")) if isinstance(x,str) else None)\n",
        "r_csv_new\n",
        "#r_csv_new_lsm=r_csv_new['lsm'].apply(lambda x: nlp(x))\n",
        "#r_csv_new_lsm['len']=r_csv_new_lsm.apply(lambda x: len(x))\n",
        "#r_csv_new_lsm.info()"
      ],
      "metadata": {
        "id": "EETbiiYK9PNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers=r_csv_new[r_csv_new['len_lsm']==8]\n",
        "outliers"
      ],
      "metadata": {
        "id": "fJdWk_EoVyTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title Distribution of Sentence Lengths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.hist(r_csv_new['len_esp'], bins=10, alpha=0.5, label='SPA')\n",
        "plt.hist(r_csv_new['len_lsm'], bins=8, alpha=0.5, label='MSL')\n",
        "plt.xlabel('Sentence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sentence Lengths')\n",
        "_ = plt.legend()\n"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "kzJLw2RUBRy9"
      }
    },
    {
      "source": [
        "# @title Distribution of Sentence Lengths by Language\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.boxplot([r_csv_new['len_esp'], r_csv_new['len_lsm']], labels=['Spanish (SPA)', 'Mexican Sign Language (MSL)'])\n",
        "plt.ylabel('Sentence Length',fontsize=20)\n",
        "plt.xlabel('Language',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.grid(True)\n",
        "\n"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "2mqcz883AZMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_processing(r_csv_new['esp'][12])"
      ],
      "metadata": {
        "id": "1O_Z_QWqZKQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "spanish_stop_words = stopwords.words('spanish')"
      ],
      "metadata": {
        "id": "iH3VZrOd2F3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def jacard_distance(s1, s2):\n",
        "  s1=re.sub(r'[^\\w\\s]','',s1)\n",
        "  s2=re.sub(r'[^\\w\\s]','',s2)\n",
        "  set1=set(word.lemma_ for word in nlp(s1) if word.is_alpha and word not in spanish_stop_words)\n",
        "  print(\"s1\",set1)\n",
        "  set2=set(word for word in s2.lower().split() if word not in string.punctuation and word not in spanish_stop_words)\n",
        "  print(\"s2\",set2)\n",
        "\n",
        "  intersection=set1.intersection(set2)\n",
        "  union=set1.union(set2)\n",
        "  return len(intersection)/len(union)\n",
        "\n"
      ],
      "metadata": {
        "id": "C29KX0pWHTfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "spanish_stop_words = stopwords.words('spanish')"
      ],
      "metadata": {
        "id": "D2jdWob_LLxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_stop_words"
      ],
      "metadata": {
        "id": "olzmw1sULPe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def cos_sim(sentence1_emb, sentence2_emb):\n",
        "\n",
        "    cos_sim = cosine_similarity(sentence1_emb, sentence2_emb)\n",
        "    return np.diag(cos_sim)"
      ],
      "metadata": {
        "id": "oM4AzIXmL2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(r_csv_new, test_size=0.2, random_state=42)\n",
        "X_test\n"
      ],
      "metadata": {
        "id": "2E2P6d-OMvq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['esp']=X_train['esp'].apply(lambda x:nlp(x))\n",
        "X_train['lsm']=X_train['lsm'].apply(lambda x:nlp(x))\n",
        "X_train['esp'] = X_train['esp'].apply(lambda sentence: [word.lemma_ for word in sentence])\n",
        "X_train['lsm'] = X_train['lsm'].apply(lambda sentence: [word.lemma_ for word in sentence])\n",
        "X_train=X_train.apply(lambda x: x.str.join(' '))\n",
        "x_test=X_test.apply(lambda x: x.str.join(' '))"
      ],
      "metadata": {
        "id": "Y0mo5XSk35jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities=[]\n",
        "for i,row in X_test.iterrows():\n",
        "  similarities.append(jacard_distance(row['esp'],row['lsm']))\n",
        "print(similarities)\n",
        "\n",
        "#calculate average jacard similarity\n",
        "avg_sim=sum(similarities)/len(similarities)\n",
        "print(avg_sim)"
      ],
      "metadata": {
        "id": "F17bfCZr7ZbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.hist(similarities, bins=15)\n",
        "plt.xlabel('Jaccard Similarity score',fontsize=20)\n",
        "plt.ylabel('Frequency',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bMWY4I5zIGTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "XX5InQEF38rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "njUcE6BvWhQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "model = TfidfVectorizer(lowercase=True,stop_words=spanish_stop_words)\n",
        "vectorizer=TfidfVectorizer(lowercase=True,stop_words=spanish_stop_words)\n",
        "X_train=pd.concat([X_train['esp'],X_train['lsm']]).unique()\n",
        "model.fit(X_train)\n",
        "sentences_esp=model.transform(X_test['esp'])\n",
        "sentences_lsm=model.transform(X_test['lsm'])\n",
        "similarities_cos_em=cos_sim(sentences_esp,sentences_lsm)\n",
        "print(similarities_cos_em)\n",
        "print(sum(similarities_cos_em)/len(similarities_cos_em))"
      ],
      "metadata": {
        "id": "GO49lVtbWZiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_esp=X_test['esp'][:7]\n",
        "X_test_lsm=X_test['lsm'][:7]\n",
        "sentences=[X_test_esp,\n",
        "           X_test_lsm]\n",
        "sentences"
      ],
      "metadata": {
        "id": "GCkURJ2cAP4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.hist(similarities_cos_em, bins=15,color='red')\n",
        "plt.xlabel('Cosine Similarity',fontsize=20)\n",
        "plt.ylabel('Frequency',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bq-ZLCKIwFWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_lsm"
      ],
      "metadata": {
        "id": "yZpsh_ObSG5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(similarities, bins=15)\n",
        "plt.xlabel('Jaccard Similarity',fontsize=20)\n",
        "plt.ylabel('Frequency',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZrY6SeClN-n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sentences = [\"This is sentence 1.\", \"This is another sentence.\", \"This is a third sentence.\"] # replace with your sentences\n",
        "\n",
        "# Embed sentences\n",
        "embeddings = np.array([nlp(sentence).vector for sentence in sentences])\n",
        "\n",
        "# Calculate cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(similarity_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=sentences, yticklabels=sentences)\n",
        "plt.title(\"Cosine Similarity Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bvle25JGPCW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}