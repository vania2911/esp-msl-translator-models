{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vania2911/esp-msl-translator-models/blob/main/Model_M2_split_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOgjvX4uM-uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1359edba-7cbb-4431-f11b-e54f9992c849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B4NDy2fuOfp"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.26.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYolSfIMijVp",
        "outputId": "b4e0cf62-40b3-4923-85d7-74ce975a2432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip2_RFlvKMQ3"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZO-wBhf20nz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2ikEL5qVUjp"
      },
      "outputs": [],
      "source": [
        "#!pip install \"transformers[sentencepiece]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgfohAFV2vzA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpGvVcEDBmwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690d0e0d-54f6-4c86-92f9-b9351c3514ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GvGpMZ2Bxz9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "my_dataset=load_dataset(\"csv\",data_files=\"/content/drive/MyDrive/doctorado/paper_scientificdata/esp-lsm.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofx2g-h-t_Jk"
      },
      "outputs": [],
      "source": [
        "def extract_languages(examples):\n",
        "  inputs=[ex for ex in examples['esp']]\n",
        "  targets=[ex for ex in examples['lsm']]\n",
        "  return {\"inputs\":inputs , \"targets\":targets}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q35mf0wJeSaX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUypX3KevN8z"
      },
      "outputs": [],
      "source": [
        "my_dataset=my_dataset.map(extract_languages,batched=True, remove_columns=[\"esp\",\"lsm\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmg1MIQwv7W0"
      },
      "outputs": [],
      "source": [
        "my_dataset=my_dataset.remove_columns(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxM3AlqKwDLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b60850f-041c-412b-d54a-b01cc1e36d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "my_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpSPDg-KeeM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e298e3d-52d6-41d5-aeba-ad86b26b1d6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inputs': 'yo voy', 'targets': 'yo ir'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "my_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX1omy8YIJ2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06a7f59-a3c1-46a4-d682-15e1be61b71b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 2400\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 600\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "split_dataset=my_dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
        "split_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flecf-mYIa-f"
      },
      "outputs": [],
      "source": [
        "split_dataset['validation']=split_dataset.pop(\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ojAKxozI8c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bef6670-cbd4-43ba-efd7-f643a83cb421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "test_valid=split_dataset['validation'].train_test_split(test_size=0.5)\n",
        "test_valid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import DatasetDict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pij-SCfCE_HF",
        "outputId": "4dcc4c6c-b6b6-4194-8fdf-64b2b5f6e022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_split_dataset=DatasetDict({\n",
        "    'train':split_dataset['train'],\n",
        "    'validation':test_valid['train'],\n",
        "    'test':test_valid['test']\n",
        "})\n",
        "new_split_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wNIzakPFCN2",
        "outputId": "23f49222-4c03-4f65-9949-b1409d2cb903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 2400\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['inputs', 'targets'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zr405oGOAaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cb645c-31f1-4106-d085-1d4bdcf98768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfwBk0HOwtC0"
      },
      "source": [
        "##Create tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xycw3MeX4gv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "0d8b0dd5fab34640976b6ba1985138fd",
            "635ccc59cb884d92838878850caf1144",
            "a6fe772e5bd24b06bdd466e0fe8ec055",
            "770a9a7d21c9422cb2874200ddc5c595",
            "d67e9fc7ade346afa00a75d00b02c41b",
            "103169bb646945b68f8d7d6f6d9744e8",
            "bc95a85a48e940e0a24b9e6f1bccb7ab",
            "48e518d4a2cf4d1f8d021d29a5ec3fe5",
            "72064ae2af364427be9da97a78377072",
            "ee9727b985a44caf8eec89f98878d16f",
            "d1520b4fdf724c3b8b1e172e7225b880",
            "370bff4a7508448aadb1f2b14e5a1a16",
            "0a1bc785b7424d71a4a4a8096c1a1961",
            "158fd57097fd497497d5b7a5f3885f69",
            "4cbfd957f8104ebaaa96688fd638099b",
            "0c6fcc8b0a004337b7a9038a7ede2a3b",
            "3c0cb241c8814ac084199253bc7c43a4"
          ]
        },
        "outputId": "24ca4bb5-c3c2-4df6-ec99-9c656637a988"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d8b0dd5fab34640976b6ba1985138fd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "#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\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yt97GRhqSMZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62DOWl53UiZQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48pji9EbOS0y"
      },
      "outputs": [],
      "source": [
        "#from transformers import MBartTokenizer\n",
        "#tokenizer=MBartTokenizer.from_pretrained('facebook/mbart-large-cc25',src_lang='es_XX', tgt_lang='es_XX')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"vgaraujov/bart-base-spanish\")\n",
        "from transformers import AutoModelForSeq2SeqLM,GenerationConfig\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"vgaraujov/bart-base-spanish\")\n",
        "\n",
        "translation_generation_config = GenerationConfig(\n",
        "    num_beams=4,\n",
        "    early_stopping=True,\n",
        "    max_length=20,\n",
        "    decoder_start_token_id=0,\n",
        "    eos_token_id=model.config.eos_token_id,\n",
        "    pad_token=model.config.pad_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "uIrU4J401o1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd66691-d003-4696-e077-d3b2c9ddb460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading file vocab.json from cache at None\n",
            "loading file merges.txt from cache at None\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"vgaraujov/bart-base-spanish\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/model.safetensors\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at vgaraujov/bart-base-spanish and are newly initialized: ['model.shared.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZQuoXE298A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3TpfeuHf56N"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ-uNTKyL9Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97e6da0-821c-4ec1-fae2-c3becdedc184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁tu', '▁amigo', '▁es', '▁desesperado', '</s>']\n",
            "['<s>', '▁amigo', '▁tuyo', '▁desesperado', '▁así', '</s>']\n"
          ]
        }
      ],
      "source": [
        "sample=split_dataset['train'][10]\n",
        "sample\n",
        "inputs=tokenizer(sample['inputs'])\n",
        "targets=tokenizer(sample['targets'])\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(inputs['input_ids']))\n",
        "print(tokenizer.convert_ids_to_tokens(targets['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtlM54_iVwSU"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(example):\n",
        "\n",
        "  #if spa_tokenizer.pad_token_id is None:\n",
        "   # spa_tokenizer.pad_token = \"<pad>\"\n",
        "    #spa_tokenizer.pad_token_id = spa_tokenizer.convert_tokens_to_ids(spa_tokenizer.pad_token)\n",
        "  input=[ex for ex in example['inputs']]\n",
        "  label=[ex for ex in example['targets']]\n",
        "\n",
        "  model_inputs=tokenizer(\n",
        "      input,\n",
        "      text_target=label,\n",
        "      max_length=128,\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_tensors=\"pt\"\n",
        "\n",
        "  )\n",
        "\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT64UyDLzceX"
      },
      "outputs": [],
      "source": [
        "small_train_dataset=new_split_dataset['train'].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset=new_split_dataset['validation'].shuffle(seed=42).select(range(100))\n",
        "small_eval_dataset=new_split_dataset['validation'].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiLtLOO9Hsbz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqFAj3yQGhnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a7a74dd3cbb14fa3afa7dc2527114aee",
            "7ad073f22686411e9e541a33fc938257",
            "897a8362c2334501b5ee98d03773a75e",
            "8296ed2754d34574b9919e50264290db",
            "500d63950d02476c815d3ab274f32fbb",
            "1b1fbaca5b0646989b4106dd3d9bb1d1",
            "37571fdcdc70462db11ad3c0aa96d0ad",
            "6c3195d2b77743a9a4ca4d55b9dc540a",
            "dcd16a0f508b497584f8c1e3d568a59a",
            "0cfca797c05343e3904420bc36393bca",
            "0bdd0e4587d7461fa397b4f9b1cc03de",
            "5551ca10a2484f0084dc82ad5975e62c",
            "d1c72eafcbcb4c9ea8e0924cca78b55a",
            "d5ce4392807747deae3d5c5c7cb8f39f",
            "e0c3ddd59ad745089702ffe4f42cc804",
            "c958e8fd0f5b48f7a741da9a56c63c92",
            "453376ae9924425a9106678b79d13499",
            "10a4ecb669d649b8ad60cfaa56480a2d",
            "d71b37807b8948f2be57cbc71f36cf8f",
            "63a170db561440138f7116b0b4e811bb",
            "b6b2606e15f44d8aa0b43c7abfecaa11",
            "2c59660425c5417597ede088d5c79696"
          ]
        },
        "outputId": "6385033d-e442-4cf2-ed77-518938fdd8b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a74dd3cbb14fa3afa7dc2527114aee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5551ca10a2484f0084dc82ad5975e62c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_tokenized=new_split_dataset['train'].map(preprocess_function, batched=True)\n",
        "validation_tokenized=new_split_dataset['validation'].map(preprocess_function, batched=True)\n",
        "test_tokenized=new_split_dataset['test'].map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch=data_collator([train_tokenized_complete[i] for i in range(1,4)])\n",
        "#batch.keys()"
      ],
      "metadata": {
        "id": "BtO_j1KZ-BlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWeIsSr98q04"
      },
      "outputs": [],
      "source": [
        "#from transformers import MBartForConditionalGeneration\n",
        "#model=MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-cc25\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model=AutoModelForSeq2SeqLM.from_pretrained(\"vgaraujov/bart-base-spanish\")"
      ],
      "metadata": {
        "id": "TySmNL8y2Kfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e7bce1-c209-420e-e0c6-d258e120fdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"vgaraujov/bart-base-spanish\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/model.safetensors\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at vgaraujov/bart-base-spanish and are newly initialized: ['model.shared.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--vgaraujov--bart-base-spanish/snapshots/1f2ce74d4ca5c196627651d66a444f27378d30cb/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4uYi1JpTuQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a8be9-b084-46f8-920f-c7a13e7183f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxUYfMcHNehN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca96593f-25cb-40e2-9822-f253b37971a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "training_args=Seq2SeqTrainingArguments(\n",
        "    output_dir=\"esp-to-lsm-barto-model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    per_device_train_batch_size=32,\n",
        "    #auto_find_batch_size=True,\n",
        "    predict_with_generate=True,\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=1.5e-5,\n",
        "    logging_steps=20,\n",
        "    weight_decay=0.01,\n",
        "    #warmup_steps=300,\n",
        "    save_total_limit=3,\n",
        "    overwrite_output_dir=True,\n",
        "    push_to_hub=True,\n",
        "    fp16=True, # True if GPU\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-awZx5c8_eQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcdbadf-dc5d-429b-8810-ad6c6d7016b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUhlGP71sjoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ede1c2-6842-47c3-ebd3-b48621ee327c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCcTcxo4zfCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47154e81-9de0-44a5-b7f5-650077fe2c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtxaiOaUzVYo"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "ter_metric = evaluate.load(\"ter\")\n",
        "rouge_metric = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9x2KW12z7eA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds =tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100s in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels,tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    ter_score=ter_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    rouge=rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    return {\"bleu\": bleu[\"score\"],\"rouge\":rouge,\"ter\":ter_score['score']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn_cTH_H_pKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b240835-afd3-4bff-da67-567f8d0ea046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/content/esp-to-lsm-barto-model is already a clone of https://huggingface.co/vania2911/esp-to-lsm-barto-model. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/esp-to-lsm-barto-model is already a clone of https://huggingface.co/vania2911/esp-to-lsm-barto-model. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:593: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=validation_tokenized,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf32IeIIWFjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "214aa3cb-e86a-49f7-f783-d972ed648a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.474864551026316, 'rouge2': 0.0895684685684685, 'rougeL': 0.4106067984303282, 'rougeLsum': 0.4111078785049378}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 13.999181747436523,\n",
              " 'eval_bleu': 1.9973081506219217,\n",
              " 'eval_rouge': {'rouge1': 0.474864551026316,\n",
              "  'rouge2': 0.0895684685684685,\n",
              "  'rougeL': 0.4106067984303282,\n",
              "  'rougeLsum': 0.4111078785049378},\n",
              " 'eval_ter': 88.10408921933085,\n",
              " 'eval_runtime': 7.4146,\n",
              " 'eval_samples_per_second': 40.461,\n",
              " 'eval_steps_per_second': 1.349}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "trainer.evaluate(max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stzy0DuYONTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cabb023-ac76-408f-ccaa-141bf9db2a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2400\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1500\n",
            "  Number of trainable parameters = 139419648\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 13:02, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Rouge</th>\n",
              "      <th>Ter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.180100</td>\n",
              "      <td>0.053930</td>\n",
              "      <td>29.711387</td>\n",
              "      <td>{'rouge1': 0.7345039307098129, 'rouge2': 0.5117211122211125, 'rougeL': 0.6920450246920837, 'rougeLsum': 0.6917017405252704}</td>\n",
              "      <td>48.698885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.024312</td>\n",
              "      <td>68.653074</td>\n",
              "      <td>{'rouge1': 0.8650428833149424, 'rouge2': 0.7422672235172237, 'rougeL': 0.8558077203297794, 'rougeLsum': 0.8557997277776692}</td>\n",
              "      <td>18.866171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.023800</td>\n",
              "      <td>0.018069</td>\n",
              "      <td>73.902378</td>\n",
              "      <td>{'rouge1': 0.9076046423619955, 'rouge2': 0.8112917314167318, 'rougeL': 0.9029955371425962, 'rougeLsum': 0.9032938360658951}</td>\n",
              "      <td>13.940520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.015970</td>\n",
              "      <td>76.614574</td>\n",
              "      <td>{'rouge1': 0.9205966876260996, 'rouge2': 0.8325669053169056, 'rougeL': 0.9148529626691393, 'rougeLsum': 0.9153342229665762}</td>\n",
              "      <td>13.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>0.015623</td>\n",
              "      <td>78.339558</td>\n",
              "      <td>{'rouge1': 0.929181029210441, 'rouge2': 0.8567184667184671, 'rougeL': 0.9250333914451565, 'rougeLsum': 0.9248940386955096}</td>\n",
              "      <td>11.710037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>0.013701</td>\n",
              "      <td>79.046078</td>\n",
              "      <td>{'rouge1': 0.9284243662111307, 'rouge2': 0.8598646446146447, 'rougeL': 0.9243404177521828, 'rougeLsum': 0.9244574099647634}</td>\n",
              "      <td>11.617100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>82.328440</td>\n",
              "      <td>{'rouge1': 0.9416226110490817, 'rouge2': 0.8737761220261224, 'rougeL': 0.9374446528417115, 'rougeLsum': 0.9382127507568687}</td>\n",
              "      <td>10.130112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>0.013259</td>\n",
              "      <td>81.272395</td>\n",
              "      <td>{'rouge1': 0.9374726357520476, 'rouge2': 0.8655512543012546, 'rougeL': 0.9330040732687792, 'rougeLsum': 0.9330111326581916}</td>\n",
              "      <td>10.408922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.012493</td>\n",
              "      <td>80.937685</td>\n",
              "      <td>{'rouge1': 0.9409313461592872, 'rouge2': 0.8717704980204982, 'rougeL': 0.9359087377763852, 'rougeLsum': 0.9363485895912368}</td>\n",
              "      <td>10.130112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.012527</td>\n",
              "      <td>81.216500</td>\n",
              "      <td>{'rouge1': 0.9380090622884738, 'rouge2': 0.866998140748141, 'rougeL': 0.9336646751940871, 'rougeLsum': 0.9341928028398617}</td>\n",
              "      <td>10.315985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.012323</td>\n",
              "      <td>82.291353</td>\n",
              "      <td>{'rouge1': 0.9462954802049229, 'rouge2': 0.8791352737676269, 'rougeL': 0.9424912837706958, 'rougeLsum': 0.9428021973439931}</td>\n",
              "      <td>9.479554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>82.139004</td>\n",
              "      <td>{'rouge1': 0.9430502719817737, 'rouge2': 0.873168741933448, 'rougeL': 0.9384727836090067, 'rougeLsum': 0.9391153484744819}</td>\n",
              "      <td>9.758364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.012135</td>\n",
              "      <td>81.511100</td>\n",
              "      <td>{'rouge1': 0.9433854187751248, 'rouge2': 0.8734352591852592, 'rougeL': 0.9382403832550894, 'rougeLsum': 0.9391199941126414}</td>\n",
              "      <td>9.851301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.011974</td>\n",
              "      <td>81.799087</td>\n",
              "      <td>{'rouge1': 0.9413324633313025, 'rouge2': 0.8663211804535336, 'rougeL': 0.9377540444734718, 'rougeLsum': 0.9381450086291419}</td>\n",
              "      <td>9.944238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>0.011682</td>\n",
              "      <td>83.264902</td>\n",
              "      <td>{'rouge1': 0.9455139253448078, 'rouge2': 0.8779724719724722, 'rougeL': 0.9423062373356493, 'rougeLsum': 0.9430993151728446}</td>\n",
              "      <td>9.107807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.012105</td>\n",
              "      <td>82.631257</td>\n",
              "      <td>{'rouge1': 0.9444912304900699, 'rouge2': 0.874740174313704, 'rougeL': 0.9399545093565994, 'rougeLsum': 0.9407451758910739}</td>\n",
              "      <td>9.665428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.011826</td>\n",
              "      <td>83.150130</td>\n",
              "      <td>{'rouge1': 0.9443079410126627, 'rouge2': 0.8739764657999955, 'rougeL': 0.9406166388937288, 'rougeLsum': 0.941211772561231}</td>\n",
              "      <td>9.479554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.011850</td>\n",
              "      <td>83.559949</td>\n",
              "      <td>{'rouge1': 0.9444137594431712, 'rouge2': 0.8779277574277575, 'rougeL': 0.9421305419296906, 'rougeLsum': 0.9425740897103128}</td>\n",
              "      <td>9.293680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>0.011848</td>\n",
              "      <td>83.484328</td>\n",
              "      <td>{'rouge1': 0.9465982741315557, 'rouge2': 0.8811424501424505, 'rougeL': 0.9436887519228851, 'rougeLsum': 0.9443445977540404}</td>\n",
              "      <td>9.107807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>83.683430</td>\n",
              "      <td>{'rouge1': 0.9460428088566635, 'rouge2': 0.882022510713687, 'rougeL': 0.943717327148829, 'rougeLsum': 0.9444284172999342}</td>\n",
              "      <td>9.107807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.7345039307098129, 'rouge2': 0.5117211122211125, 'rougeL': 0.6920450246920837, 'rougeLsum': 0.6917017405252704}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-75\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-75/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-75/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-75/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-75/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-75/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-675] due to args.save_total_limit\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-750] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.8650428833149424, 'rouge2': 0.7422672235172237, 'rougeL': 0.8558077203297794, 'rougeLsum': 0.8557997277776692}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-150\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-150/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-150/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-150/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-150/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-825] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9076046423619955, 'rouge2': 0.8112917314167318, 'rougeL': 0.9029955371425962, 'rougeLsum': 0.9032938360658951}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-225\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-225/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-225/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-225/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-225/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-225/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9205966876260996, 'rouge2': 0.8325669053169056, 'rougeL': 0.9148529626691393, 'rougeLsum': 0.9153342229665762}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-300\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-300/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-300/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-300/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-75] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.929181029210441, 'rouge2': 0.8567184667184671, 'rougeL': 0.9250333914451565, 'rougeLsum': 0.9248940386955096}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-375\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-375/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-375/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-375/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-375/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-375/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-150] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9284243662111307, 'rouge2': 0.8598646446146447, 'rougeL': 0.9243404177521828, 'rougeLsum': 0.9244574099647634}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-450\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-450/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-450/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-450/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-450/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-450/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-225] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9416226110490817, 'rouge2': 0.8737761220261224, 'rougeL': 0.9374446528417115, 'rougeLsum': 0.9382127507568687}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-525\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-525/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-525/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-525/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-525/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-525/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9374726357520476, 'rouge2': 0.8655512543012546, 'rougeL': 0.9330040732687792, 'rougeLsum': 0.9330111326581916}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-600\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-600/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-600/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-600/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-375] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9409313461592872, 'rouge2': 0.8717704980204982, 'rougeL': 0.9359087377763852, 'rougeLsum': 0.9363485895912368}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-675\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-675/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-675/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-675/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-675/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-675/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-450] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9380090622884738, 'rouge2': 0.866998140748141, 'rougeL': 0.9336646751940871, 'rougeLsum': 0.9341928028398617}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-750\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-750/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-750/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-750/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-750/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-750/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-525] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9462954802049229, 'rouge2': 0.8791352737676269, 'rougeL': 0.9424912837706958, 'rougeLsum': 0.9428021973439931}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-825\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-825/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-825/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-825/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-825/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-825/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9430502719817737, 'rouge2': 0.873168741933448, 'rougeL': 0.9384727836090067, 'rougeLsum': 0.9391153484744819}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-900\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-900/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-900/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-900/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-675] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9433854187751248, 'rouge2': 0.8734352591852592, 'rougeL': 0.9382403832550894, 'rougeLsum': 0.9391199941126414}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-975\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-975/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-975/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-975/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-975/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-975/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-750] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9413324633313025, 'rouge2': 0.8663211804535336, 'rougeL': 0.9377540444734718, 'rougeLsum': 0.9381450086291419}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1050\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1050/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1050/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1050/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1050/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1050/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-825] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9455139253448078, 'rouge2': 0.8779724719724722, 'rougeL': 0.9423062373356493, 'rougeLsum': 0.9430993151728446}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1125\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1125/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1125/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1125/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1125/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1125/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9444912304900699, 'rouge2': 0.874740174313704, 'rougeL': 0.9399545093565994, 'rougeLsum': 0.9407451758910739}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1200\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1200/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1200/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1200/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1200/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1200/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-975] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9443079410126627, 'rouge2': 0.8739764657999955, 'rougeL': 0.9406166388937288, 'rougeLsum': 0.941211772561231}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1275\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1275/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1275/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1275/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1275/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1275/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-1050] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9444137594431712, 'rouge2': 0.8779277574277575, 'rougeL': 0.9421305419296906, 'rougeLsum': 0.9425740897103128}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1350\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1350/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1350/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1350/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1350/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1350/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-1125] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9465982741315557, 'rouge2': 0.8811424501424505, 'rougeL': 0.9436887519228851, 'rougeLsum': 0.9443445977540404}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1425\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1425/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1425/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1425/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1425/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1425/special_tokens_map.json\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-1200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9460428088566635, 'rouge2': 0.882022510713687, 'rougeL': 0.943717327148829, 'rougeLsum': 0.9444284172999342}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to esp-to-lsm-barto-model/checkpoint-1500\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1500/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/checkpoint-1500/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/checkpoint-1500/special_tokens_map.json\n",
            "Deleting older checkpoint [esp-to-lsm-barto-model/checkpoint-1275] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=0.1559046092182398, metrics={'train_runtime': 782.8083, 'train_samples_per_second': 61.318, 'train_steps_per_second': 1.916, 'total_flos': 3658418749440000.0, 'train_loss': 0.1559046092182398, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ4xvxxU8diw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650,
          "referenced_widgets": [
            "91bddb341ddd431982625ffc11063b91",
            "c72b2309460b4458a9d0ce6f3c248cdf",
            "cc464f5f15424562b9485b734df0fc3e",
            "c97df095857a43768603bdb77fd05c28",
            "aff035ed7c834cabb37fc853bd91c81f",
            "3dbac482437a4fa5a57518936b1b102e",
            "b1507b8d206c498ab2b2bf855a7cbd8f",
            "5a3faa87104f468996ba41e037872295",
            "41d1dd8a0d18496bb7c436084afccc22",
            "a60e12d3b34c4e38af813abf52e31d1d",
            "f6606743fc484ce5a1c04c8f0cbab004",
            "7da10d5f4ba24231b227b115f6ca3377",
            "c5c099c82caf4cec9a8ec3425c9448c1",
            "62812dbff4aa4109802328184edaedd8",
            "8c4da1141bcc4a75847ed280ee60f9fd",
            "042412ff12d14b948a6e52ff7b4222ef",
            "72f483b4d8ed45d191430512ab136c40",
            "e2a28397534b4228adcbe8b65b018db5",
            "fd60746bbbcd4ebe9999a11d4459bfb9",
            "68c7681eeb9a49a79514c3872a9145dc",
            "c41fe32e22414b84bb6bb745d7d75d31",
            "3e853e0a7b034f378e286f5371b7a1ad"
          ]
        },
        "outputId": "13cd25ea-c5eb-4106-9174-16284ac0b508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to esp-to-lsm-model-barto\n",
            "Configuration saved in esp-to-lsm-model-barto/config.json\n",
            "Configuration saved in esp-to-lsm-model-barto/generation_config.json\n",
            "Model weights saved in esp-to-lsm-model-barto/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-model-barto/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-model-barto/special_tokens_map.json\n",
            "Saving model checkpoint to esp-to-lsm-barto-model\n",
            "Configuration saved in esp-to-lsm-barto-model/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n",
            "WARNING:huggingface_hub.repository:The progress bars may be unreliable.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 1.00/532M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91bddb341ddd431982625ffc11063b91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file runs/Oct24_16-26-11_0b0e597821aa/events.out.tfevents.1729787192.0b0e597821aa.8338.5:   0%|        …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7da10d5f4ba24231b227b115f6ca3377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/vania2911/esp-to-lsm-barto-model\n",
            "   1145d6c..2229985  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/vania2911/esp-to-lsm-barto-model\n",
            "   1145d6c..2229985  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 83.68342976097799}, {'name': 'Rouge', 'type': 'rouge', 'value': {'rouge1': 0.9460428088566635, 'rouge2': 0.882022510713687, 'rougeL': 0.943717327148829, 'rougeLsum': 0.9444284172999342}}]}\n",
            "To https://huggingface.co/vania2911/esp-to-lsm-barto-model\n",
            "   2229985..770f53f  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/vania2911/esp-to-lsm-barto-model\n",
            "   2229985..770f53f  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(\"esp-to-lsm-model-barto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtve5Lzkw_ZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f100124-8f9e-427e-cc76-d2627d4ef1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to esp-to-lsm-barto-model\n",
            "Configuration saved in esp-to-lsm-barto-model/config.json\n",
            "Configuration saved in esp-to-lsm-barto-model/generation_config.json\n",
            "Model weights saved in esp-to-lsm-barto-model/pytorch_model.bin\n",
            "tokenizer config file saved in esp-to-lsm-barto-model/tokenizer_config.json\n",
            "Special tokens file saved in esp-to-lsm-barto-model/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 83.68342976097799}, {'name': 'Rouge', 'type': 'rouge', 'value': {'rouge1': 0.9460428088566635, 'rouge2': 0.882022510713687, 'rougeL': 0.943717327148829, 'rougeLsum': 0.9444284172999342}}]}\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install latex"
      ],
      "metadata": {
        "id": "YNjQQoidMH_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072f6142-acf4-45bc-bccf-5f2bccb0412f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: latex in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: tempdir in /usr/local/lib/python3.10/dist-packages (from latex) (0.7.1)\n",
            "Requirement already satisfied: data in /usr/local/lib/python3.10/dist-packages (from latex) (0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from latex) (1.0.0)\n",
            "Requirement already satisfied: shutilwhich in /usr/local/lib/python3.10/dist-packages (from latex) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data->latex) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data->latex) (4.4.2)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.10/dist-packages (from data->latex) (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vania2911/esp-to-lsm-barto-model\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"vania2911/esp-to-lsm-barto-model\")"
      ],
      "metadata": {
        "id": "Gp0f96ZjEXZc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "217c4ba1053a42cf8f54958535cc873c",
            "a990451eea064ef29be2c5024079fe20",
            "3957c71565674a409524597e464a1c6a",
            "22d576856e5e4c3d8e5067dd6e033416",
            "8683985822ec44079ce3d0a636cfecab",
            "511a01a81c894dd59ea02772f38591bd",
            "c3f048367cc14515906e892fdc119163",
            "687ac425500345899ac931625a8b079c",
            "c7a0464c7be844a2b7aab9ce2ff37af8",
            "6bba3d8b73384cbaa10b8ccc9c7a765d",
            "50f06748a5de4bc8b263706bcb8e6f87"
          ]
        },
        "outputId": "a46b1055-3454-4a03-fcd7-282b9187abbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"vania2911/esp-to-lsm-barto-model\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "217c4ba1053a42cf8f54958535cc873c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/pytorch_model.bin\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at vania2911/esp-to-lsm-barto-model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--vania2911--esp-to-lsm-barto-model/snapshots/770f53f7d41c2f7674b3baa4b46b95f13eb662da/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text2text-generation\", model=\"VaniLara/esp-to-lsm-mbart-model\")"
      ],
      "metadata": {
        "id": "Yq1dX4HgvwKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "89d361de-58a9-4f13-d58d-c5e4f5503e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "VaniLara/esp-to-lsm-mbart-model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/VaniLara/esp-to-lsm-mbart-model/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1753\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1675\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-671a78b3-3b6fdcd16bc85a5770cc6777;2cd9c513-ed1b-49a5-b138-a96a888393d9)\n\nRepository Not Found for url: https://huggingface.co/VaniLara/esp-to-lsm-mbart-model/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-1ba1c2d191f2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text2text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VaniLara/esp-to-lsm-mbart-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mhub_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_commit_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mhub_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_commit_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: VaniLara/esp-to-lsm-mbart-model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ZZrof9KRuyf",
        "outputId": "973158a3-fabd-457c-c06a-98a5b41756ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Trainer is attempting to log a value of \"{'rouge1': 0.9584532722179784, 'rouge2': 0.898395400895401, 'rougeL': 0.9538120136943663, 'rougeLsum': 0.9538281767252356}\" of type <class 'dict'> for key \"eval/rouge\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.01038183830678463,\n",
              " 'eval_bleu': 85.41395398040652,\n",
              " 'eval_rouge': {'rouge1': 0.9584532722179784,\n",
              "  'rouge2': 0.898395400895401,\n",
              "  'rougeL': 0.9538120136943663,\n",
              "  'rougeLsum': 0.9538281767252356},\n",
              " 'eval_ter': 6.641721234798878,\n",
              " 'eval_runtime': 5.7354,\n",
              " 'eval_samples_per_second': 52.307,\n",
              " 'eval_steps_per_second': 1.744,\n",
              " 'epoch': 20.0}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texlive-full"
      ],
      "metadata": {
        "id": "i4Sewuh2L-Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "6BNLgr1yL6xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/esp-to-lsm-barto-model/checkpoint-1615/trainer_state.json\", 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "hCeGlUkTLwD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive-latex-extra texlive-fonts-recommended dvipng cm-super\n",
        "!latex --version"
      ],
      "metadata": {
        "id": "YUOWbT_sMSL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aa057fd-9bac-4af1-e3fd-f6a8450bd826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 ghostscript libapache-pom-java libcommons-logging-java\n",
            "  libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common libidn12 libijs-0.35\n",
            "  libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2 libteckit0\n",
            "  libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base texlive-binaries texlive-latex-base\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa xfonts-encodings\n",
            "  xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf ghostscript-x libavalon-framework-java\n",
            "  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java poppler-utils\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper perl-tk xpdf\n",
            "  | pdf-viewer xzdec texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n",
            "  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-luatex texlive-pstricks dot2tex prerex texlive-pictures-doc\n",
            "  vprerex default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal dvipng dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern\n",
            "  fonts-noto-mono fonts-texgyre fonts-urw-base35 ghostscript libapache-pom-java\n",
            "  libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2\n",
            "  libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base texlive-binaries\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra texlive-latex-recommended\n",
            "  texlive-pictures texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 57 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 195 MB of archives.\n",
            "After this operation, 613 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super-minimal all 0.3.4-17 [5,777 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super all 0.3.4-17 [20.2 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.9 [49.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvipng amd64 1.15-1.1 [78.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.7 [50.1 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.7 [5,113 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Fetched 195 MB in 14s (13.7 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123622 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../06-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../07-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../10-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../11-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../12-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../13-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../14-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../15-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../16-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../17-cm-super-minimal_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-17) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../18-pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../19-cm-super_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super (0.3.4-17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../20-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../21-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../22-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../23-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../24-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../25-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../26-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../27-dvipng_1.15-1.1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1.1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../29-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../30-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../31-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../32-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../33-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../34-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../35-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../36-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../37-ruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.7) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../38-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../39-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../40-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../41-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../42-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../43-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../44-libruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../45-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../46-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../47-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../48-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../49-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../50-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../51-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../52-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../53-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../54-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../55-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../56-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up dvipng (1.15-1.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up cm-super-minimal (0.3.4-17) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up cm-super (0.3.4-17) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.7) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "pdfTeX 3.141592653-2.6-1.40.22 (TeX Live 2022/dev/Debian)\n",
            "kpathsea version 6.3.4/dev\n",
            "Copyright 2021 Han The Thanh (pdfTeX) et al.\n",
            "There is NO warranty.  Redistribution of this software is\n",
            "covered by the terms of both the pdfTeX copyright and\n",
            "the Lesser GNU General Public License.\n",
            "For more information about these matters, see the file\n",
            "named COPYING and the pdfTeX source.\n",
            "Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.\n",
            "Compiled with libpng 1.6.37; using libpng 1.6.37\n",
            "Compiled with zlib 1.2.11; using zlib 1.2.11\n",
            "Compiled with xpdf version 4.03\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x100 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAB3CAYAAADSB/HlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJV0lEQVR4nO3dP28a2R7G8Z+zQUiW7EzQrawQRVOk2org7aPgbLEtJNLtjXsXEFeJKxZL9wWM/QqcoU2kDUgpowhBdVsmK1lyZ0xA1xLixucWXLAxxubPYQ7jfD9StGYYe06enXk8PjMZLymllAAAjLhnegAA8DOjhAHAIEoYAAyihAHAIEoYAAyihAHAIEoYAAyihAHAoPumByAicn5+LsfHx7KysiJLS0umhwMAM1NKSavVkrW1Nbl3b/T57kKU8PHxsUSjUdPDAADtjo6O5NGjRyPfX4gSXllZERGRb9++yZcvX+Tly5cSCoUMj8qsTqcjnz59Igshi8vIoisIOTSbTYlGo/1+G2UhSrg3BbGysiLLy8uyurq6sMH6pdPpkMX/kcUFsugKUg63TbFyYQ4ADFqIM+FZPHnzwdft/f3nH75uD8DdxpkwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABhECQOAQZQwABg0UQlXq1V59uzZ0HLP82Rvb08KhYLs7e1Jo9HQNT4AuNPG/pX3hUJBbNuWarU69F4qlZJKpSIi3ULe3NwU13X1jRIA7qixSziZTF673PO8gde2bUupVJptVADwk5h5TrhUKkkkEhlYFolErj1jBgAMGvtMeJRR87/1en3k57TbbWm32/3XzWZTREQ6nc7Af8cR/kWNva4Ok4xNx3b82t4iI4sLZNEVhBzGHdvMJTzKTRfncrmc7O7uDi3//PmzLC8vS7FYHHs7e79NM7rpffz40dftTZLFXUcWF8iia5FzODs7G2u9mUvYsqyhs956vS6WZY38nJ2dHdne3u6/bjabEo1G5fnz5/L161fZ2NiQUCg01vZ/fffXVOOe1r/f/e7LdjqdjhSLxYmyuKvI4gJZdAUhh95P+LeZuYQTiYQ4jjO0PB6Pj/yccDgs4XB4aHkvzFAoNHaw7R9LY45UD7//h0+SxV1HFhfIomuRcxh3XFNdmLs81WDb9sB7nudJPB6/8UwYANA19plwqVTqz7/kcjlZX1/v37bmuq5ks1lZX1+XcrnMPcIAMKaxSziRSEgikZB8Pj/0nm3b/eWj7icGAAzj2REAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYBAlDAAGUcIAYNB90wMImidvPviynfAvSvZ+82VTAAziTBgADKKEAcAgShgADNI2J+x5nhQKBbFtWzzPk3Q6LZZl6fryP61f3/0l7R9Lvm3v7z//8G1bwDSevPnQv2bix/Ex72NCWwmnUimpVCoi0i3kzc1NcV1X15cHgDtJy3SE53kDr23bllKppONLA8CdpqWES6WSRCKRgWWRSESq1aqOLw8Ad5aW6YhGo3Ht8nq9fu3ydrst7Xa7//r79+/99c/OzuTk5ERCodBY277/3/9MNtiAuH+u5OzsXO537smPc//mhE9OTnzb1rg6nc7E+8VdRRbdY97P42PaY6LVaomIiFLqxvXm+o81RpVzLpeT3d3doeVPnz6d53AC558GtvmPfxnYKDAFv46PWY+JVqslDx48GPm+lhK2LGvorLder4+8O2JnZ0e2t7f7r8/Pz6Ver0soFJLHjx/L0dGRrK6u6hhaYDWbTYlGo2QhZHEZWXQFIQellLRaLVlbW7txPS0lnEgkxHGcoeXxePza9cPhsITD4YFllmVJs9kUEZHV1dWFDdZvZHGBLC6QRdei53DTGXCPlgtztm0PvPY8T+LxOPcJA8AttM0Ju64r2WxW1tfXpVwuc48wAIxBWwnbti35fF5ERJLJ5FRfIxwOy9u3b4emKn5GZHGBLC6QRdddymFJ3Xb/BABgbniADwAYRAkDgEG+/GaNSZ6wdtu61WpVNjc3+w8LChpdWVSr1f7zOcrlshwcHATubhRdWfRyaDQaUi6X5fXr1xKLxXz6W8xO5/HRk81mZWdn56fdJ3qPTIjFYuJ5njQajcXdJ5QPYrFY/+NaraaSyeRU67quqyqVivJp2HOhK4t8Pj/w8eV1g0JXFpZlqUqlopRSynEcZdv2HEY7P7py6OkdI6enp1rH6QddWaTTaSUiSkRUIpFY6Czm3ma1Wm2oICzLmmndoJawriwqlcrA59VqNSUiqlaraR7x/OjcL4rFYv9jx3EC9Q1pHseH67rKtu2FLp7r6MzCcRx1enoaiAzmPic8yRPW7vrT2HRlEYvF5ODgoL+894yOq+svMp37RSKR6C93XVe2trbmMOL50H18FAqFqW8RNU13FpZlBWI6Zu5zwpM8YW3Sp7EFjc4sLh9oh4eHkkgkArHD9ejeL6rVqhweHsrGxoak02kdQ/SFzhwajUag9oGrdGdRKBREpHvNZGtra+hf9i4KY7/yflSIs64bRLNk0dvZgnqh8qpps4jFYmLbtmSz2UCfDfZMk8P79+8D9Q1oXNNkcfkinW3bsrGxIbVaTf/gNJj7dMQkT1ib9GlsQTOPLLLZrBSLxcBlNI8sLMuSVColqVQqMN+4deVQKpXk1atX8xzq3OncJy7/tp/e3RNXfwPQoph7CV+er7vsuiesTbJuEOnOYm9vT7LZrNi2LY1GIzDFI6Ivi1KpJA8fPuwv6/3IuagH3FU694n379/L/v6+7O/vi+d5ksvlAnU9RVcW1WpVXrx4MfTeol4zmft0xG1PWKtWq2JZlti2PdHT2II4/6Uzi0Kh0P8RvNFoBO5HUV1ZRCKRgQOy93kLe0/oFbpyuFpKW1tbCz0Peh1dWVx+jo1I9yJeMplc3L7w4xaMWq2mMpmMcl1XZTKZgdtGksnkwD2vN61bLBZVJpNRItJfJ2h0ZNG7Je3yn1G38iwyXfuF67rKcRzlOI5KJpOBulVPKX05KKXU6empyufzSkRUOp3u3z8dFLqyqFQqKp/PK8dxVCaT8fFvMDke4AMABvHsCAAwiBIGAIMoYQAwiBIGAIMoYQAwiBIGAIMoYQAwiBIGAIMoYQAwiBIGAIMoYQAwiBIGAIP+B1NHYcMko8dVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_history=trainer.state.log_history\n",
        "data=pd.DataFrame(trainer_history)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "_81Q_YzpUHJX",
        "outputId": "eb15b0c3-f5d1-4fc0-de0a-1ca0d1f1e609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      loss  learning_rate  epoch  step  eval_loss  eval_bleu  \\\n",
              "0   9.7184   1.483000e-05   0.27    20        NaN        NaN   \n",
              "1   0.9057   1.463000e-05   0.53    40        NaN        NaN   \n",
              "2   0.1801   1.443000e-05   0.80    60        NaN        NaN   \n",
              "3      NaN            NaN   1.00    75   0.053930  29.711387   \n",
              "4   0.0834   1.423000e-05   1.07    80        NaN        NaN   \n",
              "..     ...            ...    ...   ...        ...        ...   \n",
              "92  0.0056   2.300000e-07  19.73  1480        NaN        NaN   \n",
              "93  0.0069   3.000000e-08  20.00  1500        NaN        NaN   \n",
              "94     NaN            NaN  20.00  1500   0.011871  83.683430   \n",
              "95     NaN            NaN  20.00  1500        NaN        NaN   \n",
              "96     NaN            NaN  20.00  1500   0.010382  85.413954   \n",
              "\n",
              "                                           eval_rouge   eval_ter  \\\n",
              "0                                                 NaN        NaN   \n",
              "1                                                 NaN        NaN   \n",
              "2                                                 NaN        NaN   \n",
              "3   {'rouge1': 0.7345039307098129, 'rouge2': 0.511...  48.698885   \n",
              "4                                                 NaN        NaN   \n",
              "..                                                ...        ...   \n",
              "92                                                NaN        NaN   \n",
              "93                                                NaN        NaN   \n",
              "94  {'rouge1': 0.9460428088566635, 'rouge2': 0.882...   9.107807   \n",
              "95                                                NaN        NaN   \n",
              "96  {'rouge1': 0.9584532722179784, 'rouge2': 0.898...   6.641721   \n",
              "\n",
              "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
              "0            NaN                      NaN                    NaN   \n",
              "1            NaN                      NaN                    NaN   \n",
              "2            NaN                      NaN                    NaN   \n",
              "3         6.2287                   48.164                  1.605   \n",
              "4            NaN                      NaN                    NaN   \n",
              "..           ...                      ...                    ...   \n",
              "92           NaN                      NaN                    NaN   \n",
              "93           NaN                      NaN                    NaN   \n",
              "94        5.8976                   50.868                  1.696   \n",
              "95           NaN                      NaN                    NaN   \n",
              "96        5.7354                   52.307                  1.744   \n",
              "\n",
              "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "0             NaN                       NaN                     NaN   \n",
              "1             NaN                       NaN                     NaN   \n",
              "2             NaN                       NaN                     NaN   \n",
              "3             NaN                       NaN                     NaN   \n",
              "4             NaN                       NaN                     NaN   \n",
              "..            ...                       ...                     ...   \n",
              "92            NaN                       NaN                     NaN   \n",
              "93            NaN                       NaN                     NaN   \n",
              "94            NaN                       NaN                     NaN   \n",
              "95       782.8083                    61.318                   1.916   \n",
              "96            NaN                       NaN                     NaN   \n",
              "\n",
              "      total_flos  train_loss  \n",
              "0            NaN         NaN  \n",
              "1            NaN         NaN  \n",
              "2            NaN         NaN  \n",
              "3            NaN         NaN  \n",
              "4            NaN         NaN  \n",
              "..           ...         ...  \n",
              "92           NaN         NaN  \n",
              "93           NaN         NaN  \n",
              "94           NaN         NaN  \n",
              "95  3.658419e+15    0.155905  \n",
              "96           NaN         NaN  \n",
              "\n",
              "[97 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c72de4e1-6d5b-4550-bcb1-c682a890a3ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epoch</th>\n",
              "      <th>step</th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_bleu</th>\n",
              "      <th>eval_rouge</th>\n",
              "      <th>eval_ter</th>\n",
              "      <th>eval_runtime</th>\n",
              "      <th>eval_samples_per_second</th>\n",
              "      <th>eval_steps_per_second</th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>total_flos</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.7184</td>\n",
              "      <td>1.483000e-05</td>\n",
              "      <td>0.27</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9057</td>\n",
              "      <td>1.463000e-05</td>\n",
              "      <td>0.53</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1801</td>\n",
              "      <td>1.443000e-05</td>\n",
              "      <td>0.80</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>75</td>\n",
              "      <td>0.053930</td>\n",
              "      <td>29.711387</td>\n",
              "      <td>{'rouge1': 0.7345039307098129, 'rouge2': 0.511...</td>\n",
              "      <td>48.698885</td>\n",
              "      <td>6.2287</td>\n",
              "      <td>48.164</td>\n",
              "      <td>1.605</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0834</td>\n",
              "      <td>1.423000e-05</td>\n",
              "      <td>1.07</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.0056</td>\n",
              "      <td>2.300000e-07</td>\n",
              "      <td>19.73</td>\n",
              "      <td>1480</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.0069</td>\n",
              "      <td>3.000000e-08</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>83.683430</td>\n",
              "      <td>{'rouge1': 0.9460428088566635, 'rouge2': 0.882...</td>\n",
              "      <td>9.107807</td>\n",
              "      <td>5.8976</td>\n",
              "      <td>50.868</td>\n",
              "      <td>1.696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>782.8083</td>\n",
              "      <td>61.318</td>\n",
              "      <td>1.916</td>\n",
              "      <td>3.658419e+15</td>\n",
              "      <td>0.155905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>0.010382</td>\n",
              "      <td>85.413954</td>\n",
              "      <td>{'rouge1': 0.9584532722179784, 'rouge2': 0.898...</td>\n",
              "      <td>6.641721</td>\n",
              "      <td>5.7354</td>\n",
              "      <td>52.307</td>\n",
              "      <td>1.744</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c72de4e1-6d5b-4550-bcb1-c682a890a3ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c72de4e1-6d5b-4550-bcb1-c682a890a3ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c72de4e1-6d5b-4550-bcb1-c682a890a3ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92deb853-9d23-48f3-be01-b09f431e54c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92deb853-9d23-48f3-be01-b09f431e54c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92deb853-9d23-48f3-be01-b09f431e54c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d435805f-04c8-4b8b-bfa7-bbf206214e83\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d435805f-04c8-4b8b-bfa7-bbf206214e83 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1240552922343279,\n        \"min\": 0.0045,\n        \"max\": 9.7184,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          9.7184,\n          0.0449,\n          0.0087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.358898943540674e-06,\n        \"min\": 3.0000000000000004e-08,\n        \"max\": 1.483e-05,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          1.4030000000000001e-05,\n          2.2300000000000002e-06,\n          1.2829999999999999e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.911103741616963,\n        \"min\": 0.27,\n        \"max\": 20.0,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          9.07,\n          5.07,\n          12.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 443,\n        \"min\": 20,\n        \"max\": 1500,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          680,\n          380,\n          940\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009331392831726546,\n        \"min\": 0.01038183830678463,\n        \"max\": 0.05393018573522568,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.05393018573522568,\n          0.011850251816213131,\n          0.012105412781238556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_bleu\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.771687409072646,\n        \"min\": 29.711387025090442,\n        \"max\": 85.41395398040652,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          29.711387025090442,\n          83.55994885766496,\n          82.63125660469416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_rouge\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_ter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.665511105004343,\n        \"min\": 6.641721234798878,\n        \"max\": 48.698884758364315,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          48.698884758364315,\n          18.866171003717472,\n          11.617100371747211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1822919151617354,\n        \"min\": 5.7287,\n        \"max\": 6.4335,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          6.2287,\n          6.2557,\n          6.0389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4956599849150842,\n        \"min\": 46.631,\n        \"max\": 52.368,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          48.164,\n          47.956,\n          49.678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.049995571232431604,\n        \"min\": 1.554,\n        \"max\": 1.746,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1.605,\n          1.715,\n          1.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 782.8083,\n        \"max\": 782.8083,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          782.8083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 61.318,\n        \"max\": 61.318,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          61.318\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.916,\n        \"max\": 1.916,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_flos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3658418749440000.0,\n        \"max\": 3658418749440000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3658418749440000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1559046092182398,\n        \"max\": 0.1559046092182398,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1559046092182398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "EVUQuKEgMVLl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "d983cb29-51eb-4c14-8d46-b262c29276ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      loss  learning_rate  epoch  step  eval_loss  eval_bleu  \\\n",
              "0   9.7184   1.483000e-05   0.27    20        NaN        NaN   \n",
              "1   0.9057   1.463000e-05   0.53    40        NaN        NaN   \n",
              "2   0.1801   1.443000e-05   0.80    60        NaN        NaN   \n",
              "3      NaN            NaN   1.00    75   0.053930  29.711387   \n",
              "4   0.0834   1.423000e-05   1.07    80        NaN        NaN   \n",
              "..     ...            ...    ...   ...        ...        ...   \n",
              "92  0.0056   2.300000e-07  19.73  1480        NaN        NaN   \n",
              "93  0.0069   3.000000e-08  20.00  1500        NaN        NaN   \n",
              "94     NaN            NaN  20.00  1500   0.011871  83.683430   \n",
              "95     NaN            NaN  20.00  1500        NaN        NaN   \n",
              "96     NaN            NaN  20.00  1500   0.010382  85.413954   \n",
              "\n",
              "                                           eval_rouge   eval_ter  \\\n",
              "0                                                 NaN        NaN   \n",
              "1                                                 NaN        NaN   \n",
              "2                                                 NaN        NaN   \n",
              "3   {'rouge1': 0.7345039307098129, 'rouge2': 0.511...  48.698885   \n",
              "4                                                 NaN        NaN   \n",
              "..                                                ...        ...   \n",
              "92                                                NaN        NaN   \n",
              "93                                                NaN        NaN   \n",
              "94  {'rouge1': 0.9460428088566635, 'rouge2': 0.882...   9.107807   \n",
              "95                                                NaN        NaN   \n",
              "96  {'rouge1': 0.9584532722179784, 'rouge2': 0.898...   6.641721   \n",
              "\n",
              "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
              "0            NaN                      NaN                    NaN   \n",
              "1            NaN                      NaN                    NaN   \n",
              "2            NaN                      NaN                    NaN   \n",
              "3         6.2287                   48.164                  1.605   \n",
              "4            NaN                      NaN                    NaN   \n",
              "..           ...                      ...                    ...   \n",
              "92           NaN                      NaN                    NaN   \n",
              "93           NaN                      NaN                    NaN   \n",
              "94        5.8976                   50.868                  1.696   \n",
              "95           NaN                      NaN                    NaN   \n",
              "96        5.7354                   52.307                  1.744   \n",
              "\n",
              "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "0             NaN                       NaN                     NaN   \n",
              "1             NaN                       NaN                     NaN   \n",
              "2             NaN                       NaN                     NaN   \n",
              "3             NaN                       NaN                     NaN   \n",
              "4             NaN                       NaN                     NaN   \n",
              "..            ...                       ...                     ...   \n",
              "92            NaN                       NaN                     NaN   \n",
              "93            NaN                       NaN                     NaN   \n",
              "94            NaN                       NaN                     NaN   \n",
              "95       782.8083                    61.318                   1.916   \n",
              "96            NaN                       NaN                     NaN   \n",
              "\n",
              "      total_flos  train_loss  \n",
              "0            NaN         NaN  \n",
              "1            NaN         NaN  \n",
              "2            NaN         NaN  \n",
              "3            NaN         NaN  \n",
              "4            NaN         NaN  \n",
              "..           ...         ...  \n",
              "92           NaN         NaN  \n",
              "93           NaN         NaN  \n",
              "94           NaN         NaN  \n",
              "95  3.658419e+15    0.155905  \n",
              "96           NaN         NaN  \n",
              "\n",
              "[97 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84c601f7-7ebf-42ff-a8b0-250797074047\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epoch</th>\n",
              "      <th>step</th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_bleu</th>\n",
              "      <th>eval_rouge</th>\n",
              "      <th>eval_ter</th>\n",
              "      <th>eval_runtime</th>\n",
              "      <th>eval_samples_per_second</th>\n",
              "      <th>eval_steps_per_second</th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>total_flos</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.7184</td>\n",
              "      <td>1.483000e-05</td>\n",
              "      <td>0.27</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9057</td>\n",
              "      <td>1.463000e-05</td>\n",
              "      <td>0.53</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1801</td>\n",
              "      <td>1.443000e-05</td>\n",
              "      <td>0.80</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>75</td>\n",
              "      <td>0.053930</td>\n",
              "      <td>29.711387</td>\n",
              "      <td>{'rouge1': 0.7345039307098129, 'rouge2': 0.511...</td>\n",
              "      <td>48.698885</td>\n",
              "      <td>6.2287</td>\n",
              "      <td>48.164</td>\n",
              "      <td>1.605</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0834</td>\n",
              "      <td>1.423000e-05</td>\n",
              "      <td>1.07</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.0056</td>\n",
              "      <td>2.300000e-07</td>\n",
              "      <td>19.73</td>\n",
              "      <td>1480</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.0069</td>\n",
              "      <td>3.000000e-08</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>83.683430</td>\n",
              "      <td>{'rouge1': 0.9460428088566635, 'rouge2': 0.882...</td>\n",
              "      <td>9.107807</td>\n",
              "      <td>5.8976</td>\n",
              "      <td>50.868</td>\n",
              "      <td>1.696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>782.8083</td>\n",
              "      <td>61.318</td>\n",
              "      <td>1.916</td>\n",
              "      <td>3.658419e+15</td>\n",
              "      <td>0.155905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1500</td>\n",
              "      <td>0.010382</td>\n",
              "      <td>85.413954</td>\n",
              "      <td>{'rouge1': 0.9584532722179784, 'rouge2': 0.898...</td>\n",
              "      <td>6.641721</td>\n",
              "      <td>5.7354</td>\n",
              "      <td>52.307</td>\n",
              "      <td>1.744</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84c601f7-7ebf-42ff-a8b0-250797074047')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84c601f7-7ebf-42ff-a8b0-250797074047 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84c601f7-7ebf-42ff-a8b0-250797074047');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-625b51af-1544-419c-a6a4-f21310f1d9a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-625b51af-1544-419c-a6a4-f21310f1d9a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-625b51af-1544-419c-a6a4-f21310f1d9a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b1671e30-17fd-495f-967d-9b9e956a09cb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b1671e30-17fd-495f-967d-9b9e956a09cb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1240552922343279,\n        \"min\": 0.0045,\n        \"max\": 9.7184,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          9.7184,\n          0.0449,\n          0.0087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.358898943540674e-06,\n        \"min\": 3.0000000000000004e-08,\n        \"max\": 1.483e-05,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          1.4030000000000001e-05,\n          2.2300000000000002e-06,\n          1.2829999999999999e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.911103741616963,\n        \"min\": 0.27,\n        \"max\": 20.0,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          9.07,\n          5.07,\n          12.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 443,\n        \"min\": 20,\n        \"max\": 1500,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          680,\n          380,\n          940\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009331392831726546,\n        \"min\": 0.01038183830678463,\n        \"max\": 0.05393018573522568,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.05393018573522568,\n          0.011850251816213131,\n          0.012105412781238556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_bleu\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.771687409072646,\n        \"min\": 29.711387025090442,\n        \"max\": 85.41395398040652,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          29.711387025090442,\n          83.55994885766496,\n          82.63125660469416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_rouge\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_ter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.665511105004343,\n        \"min\": 6.641721234798878,\n        \"max\": 48.698884758364315,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          48.698884758364315,\n          18.866171003717472,\n          11.617100371747211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1822919151617354,\n        \"min\": 5.7287,\n        \"max\": 6.4335,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          6.2287,\n          6.2557,\n          6.0389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4956599849150842,\n        \"min\": 46.631,\n        \"max\": 52.368,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          48.164,\n          47.956,\n          49.678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.049995571232431604,\n        \"min\": 1.554,\n        \"max\": 1.746,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1.605,\n          1.715,\n          1.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 782.8083,\n        \"max\": 782.8083,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          782.8083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 61.318,\n        \"max\": 61.318,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          61.318\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.916,\n        \"max\": 1.916,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_flos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3658418749440000.0,\n        \"max\": 3658418749440000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3658418749440000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1559046092182398,\n        \"max\": 0.1559046092182398,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1559046092182398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hist=pd.DataFrame(data['log_history'])\n",
        "hist=data\n",
        "\n",
        "hist=hist[['eval_loss','eval_bleu','epoch','loss','eval_rouge','eval_ter']].set_index('epoch')\n",
        "hist\n",
        "hist_flattened=pd.json_normalize(hist['eval_rouge'])\n",
        "\n",
        "hist_result=pd.concat([hist,hist_flattened])\n",
        "hist_result.drop(columns=['eval_rouge'],inplace=True)\n",
        "hist_result"
      ],
      "metadata": {
        "id": "YnNsz49aMew5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9d259b78-d8bf-42b1-9e3c-f247add06706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       eval_loss  eval_bleu    loss   eval_ter    rouge1    rouge2    rougeL  \\\n",
              "0.27         NaN        NaN  9.7184        NaN       NaN       NaN       NaN   \n",
              "0.53         NaN        NaN  0.9057        NaN       NaN       NaN       NaN   \n",
              "0.80         NaN        NaN  0.1801        NaN       NaN       NaN       NaN   \n",
              "1.00     0.05393  29.711387     NaN  48.698885       NaN       NaN       NaN   \n",
              "1.07         NaN        NaN  0.0834        NaN       NaN       NaN       NaN   \n",
              "...          ...        ...     ...        ...       ...       ...       ...   \n",
              "92.00        NaN        NaN     NaN        NaN       NaN       NaN       NaN   \n",
              "93.00        NaN        NaN     NaN        NaN       NaN       NaN       NaN   \n",
              "94.00        NaN        NaN     NaN        NaN  0.946043  0.882023  0.943717   \n",
              "95.00        NaN        NaN     NaN        NaN       NaN       NaN       NaN   \n",
              "96.00        NaN        NaN     NaN        NaN  0.958453  0.898395  0.953812   \n",
              "\n",
              "       rougeLsum  \n",
              "0.27         NaN  \n",
              "0.53         NaN  \n",
              "0.80         NaN  \n",
              "1.00         NaN  \n",
              "1.07         NaN  \n",
              "...          ...  \n",
              "92.00        NaN  \n",
              "93.00        NaN  \n",
              "94.00   0.944428  \n",
              "95.00        NaN  \n",
              "96.00   0.953828  \n",
              "\n",
              "[194 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cda89a58-a69e-4690-851c-54029ad2109e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_bleu</th>\n",
              "      <th>loss</th>\n",
              "      <th>eval_ter</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.27</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.7184</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.53</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9057</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.80</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>0.05393</td>\n",
              "      <td>29.711387</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.698885</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.07</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0834</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92.00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93.00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94.00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.946043</td>\n",
              "      <td>0.882023</td>\n",
              "      <td>0.943717</td>\n",
              "      <td>0.944428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95.00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96.00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.958453</td>\n",
              "      <td>0.898395</td>\n",
              "      <td>0.953812</td>\n",
              "      <td>0.953828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cda89a58-a69e-4690-851c-54029ad2109e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cda89a58-a69e-4690-851c-54029ad2109e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cda89a58-a69e-4690-851c-54029ad2109e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aff83c87-ec73-442e-9a46-b7bfed812e12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aff83c87-ec73-442e-9a46-b7bfed812e12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aff83c87-ec73-442e-9a46-b7bfed812e12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_004019a6-038f-4361-acf3-d60656621ada\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('hist_result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_004019a6-038f-4361-acf3-d60656621ada button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('hist_result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "hist_result",
              "summary": "{\n  \"name\": \"hist_result\",\n  \"rows\": 194,\n  \"fields\": [\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009331392831726546,\n        \"min\": 0.01038183830678463,\n        \"max\": 0.05393018573522568,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.05393018573522568,\n          0.011850251816213131,\n          0.012105412781238556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_bleu\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.771687409072646,\n        \"min\": 29.711387025090442,\n        \"max\": 85.41395398040652,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          29.711387025090442,\n          83.55994885766496,\n          82.63125660469416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1240552922343279,\n        \"min\": 0.0045,\n        \"max\": 9.7184,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          9.7184,\n          0.0449,\n          0.0087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_ter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.665511105004343,\n        \"min\": 6.641721234798878,\n        \"max\": 48.698884758364315,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          48.698884758364315,\n          18.866171003717472,\n          11.617100371747211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.047973434534666445,\n        \"min\": 0.7345039307098129,\n        \"max\": 0.9584532722179784,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.7345039307098129,\n          0.9444137594431712,\n          0.9444912304900699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08317835142671542,\n        \"min\": 0.5117211122211125,\n        \"max\": 0.898395400895401,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.5117211122211125,\n          0.8779277574277575,\n          0.874740174313704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05609346108101301,\n        \"min\": 0.6920450246920837,\n        \"max\": 0.9538120136943663,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.6920450246920837,\n          0.9421305419296906,\n          0.9399545093565994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0562989447361853,\n        \"min\": 0.6917017405252704,\n        \"max\": 0.9538281767252356,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.6917017405252704,\n          0.9425740897103128,\n          0.9407451758910739\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## bleu and ter\n",
        "metrics=hist_result.drop(columns=['loss','eval_loss','rougeL','rougeLsum','rouge1','rouge2'])\n",
        "metrics=metrics.dropna()\n",
        "metrics2=hist_result.drop(columns=['eval_bleu','eval_ter','loss','eval_loss','rougeL','rougeLsum'])\n",
        "metrics2=metrics2.dropna()\n",
        "#metrics2=metrics2[metrics2.index.isin(range(0,21))]\n",
        "metrics2=metrics2.apply(lambda x: x*100)\n",
        "\n",
        "metrics.reset_index(inplace=True)\n",
        "#metrics2=metrics2.ffill()\n",
        "#metrics2.reset_index(inplace=True)\n",
        "#metrics2=metrics2.drop(columns=['index'],inplace=True)\n",
        "metrics2.reset_index(inplace=True)\n",
        "\n",
        "#metrics2=metrics2.drop(21)\n",
        "#metrics=metrics.drop(20)\n",
        "#metrics2.loc[21]=[3,95.845327,89.839540]\n",
        "metrics2"
      ],
      "metadata": {
        "id": "RhFd8-1jeYAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "71acb40b-ebc2-4513-f446-bd52cf3ecf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    index     rouge1     rouge2\n",
              "0     3.0  73.450393  51.172111\n",
              "1     8.0  86.504288  74.226722\n",
              "2    13.0  90.760464  81.129173\n",
              "3    18.0  92.059669  83.256691\n",
              "4    22.0  92.918103  85.671847\n",
              "5    27.0  92.842437  85.986464\n",
              "6    32.0  94.162261  87.377612\n",
              "7    37.0  93.747264  86.555125\n",
              "8    41.0  94.093135  87.177050\n",
              "9    46.0  93.800906  86.699814\n",
              "10   51.0  94.629548  87.913527\n",
              "11   56.0  94.305027  87.316874\n",
              "12   60.0  94.338542  87.343526\n",
              "13   65.0  94.133246  86.632118\n",
              "14   70.0  94.551393  87.797247\n",
              "15   75.0  94.449123  87.474017\n",
              "16   79.0  94.430794  87.397647\n",
              "17   84.0  94.441376  87.792776\n",
              "18   89.0  94.659827  88.114245\n",
              "19   94.0  94.604281  88.202251\n",
              "20   96.0  95.845327  89.839540"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-071345af-9cb0-4aa6-a066-a5312fba22f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>73.450393</td>\n",
              "      <td>51.172111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.0</td>\n",
              "      <td>86.504288</td>\n",
              "      <td>74.226722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.0</td>\n",
              "      <td>90.760464</td>\n",
              "      <td>81.129173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>92.059669</td>\n",
              "      <td>83.256691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.0</td>\n",
              "      <td>92.918103</td>\n",
              "      <td>85.671847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27.0</td>\n",
              "      <td>92.842437</td>\n",
              "      <td>85.986464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>32.0</td>\n",
              "      <td>94.162261</td>\n",
              "      <td>87.377612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37.0</td>\n",
              "      <td>93.747264</td>\n",
              "      <td>86.555125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>41.0</td>\n",
              "      <td>94.093135</td>\n",
              "      <td>87.177050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>46.0</td>\n",
              "      <td>93.800906</td>\n",
              "      <td>86.699814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>51.0</td>\n",
              "      <td>94.629548</td>\n",
              "      <td>87.913527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>56.0</td>\n",
              "      <td>94.305027</td>\n",
              "      <td>87.316874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>60.0</td>\n",
              "      <td>94.338542</td>\n",
              "      <td>87.343526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>65.0</td>\n",
              "      <td>94.133246</td>\n",
              "      <td>86.632118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>70.0</td>\n",
              "      <td>94.551393</td>\n",
              "      <td>87.797247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>75.0</td>\n",
              "      <td>94.449123</td>\n",
              "      <td>87.474017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>79.0</td>\n",
              "      <td>94.430794</td>\n",
              "      <td>87.397647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>84.0</td>\n",
              "      <td>94.441376</td>\n",
              "      <td>87.792776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>89.0</td>\n",
              "      <td>94.659827</td>\n",
              "      <td>88.114245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>94.0</td>\n",
              "      <td>94.604281</td>\n",
              "      <td>88.202251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96.0</td>\n",
              "      <td>95.845327</td>\n",
              "      <td>89.839540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-071345af-9cb0-4aa6-a066-a5312fba22f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-071345af-9cb0-4aa6-a066-a5312fba22f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-071345af-9cb0-4aa6-a066-a5312fba22f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c369a66-a295-4245-bf66-68ef50c57491\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c369a66-a295-4245-bf66-68ef50c57491')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c369a66-a295-4245-bf66-68ef50c57491 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bb4ebe44-b6d4-46bc-901b-b8c56dcdfc96\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb4ebe44-b6d4-46bc-901b-b8c56dcdfc96 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics2",
              "summary": "{\n  \"name\": \"metrics2\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.33752675653618,\n        \"min\": 3.0,\n        \"max\": 96.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          3.0,\n          84.0,\n          75.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.797343453466643,\n        \"min\": 73.45039307098129,\n        \"max\": 95.84532722179785,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          73.45039307098129,\n          94.44137594431712,\n          94.44912304900699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.317835142671543,\n        \"min\": 51.17211122211125,\n        \"max\": 89.83954008954011,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          51.17211122211125,\n          87.79277574277575,\n          87.4740174313704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and eval_loss\n",
        "loss_eval_loss=hist[['eval_loss','loss']]\n",
        "eval_loss_data=loss_eval_loss['eval_loss'].dropna()\n",
        "loss_data=loss_eval_loss['loss'].dropna()\n",
        "data_new=pd.concat([eval_loss_data,loss_data],axis=1)\n",
        "data_new.columns=['eval_loss','loss']\n",
        "eval_loss_data"
      ],
      "metadata": {
        "id": "ThSRLXrmX7v0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "af0c0112-40c6-48e4-9639-b3928fc8393f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reindex on an axis with duplicate labels",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-1ea03f82133d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_loss_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_eval_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_eval_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_loss_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0meval_loss_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# _homogenize ensures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m#  - all(len(x) == len(index) for x in arrays)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;31m# Forces alignment. No need to copy data since we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;31m# are putting it into an ndarray later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_references\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5151\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5152\u001b[0m     ) -> Series:\n\u001b[0;32m-> 5153\u001b[0;31m         return super().reindex(\n\u001b[0m\u001b[1;32m   5154\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5609\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5610\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   5611\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5612\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5632\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5633\u001b[0;31m             new_index, indexer = ax.reindex(\n\u001b[0m\u001b[1;32m   5634\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5635\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4427\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4428\u001b[0m                     \u001b[0;31m# GH#42568\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4429\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex on an axis with duplicate labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4430\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4431\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which latex\n",
        "!sudo apt-get install texlive-latex-extra texlive-fonts-recommended dvipng cm-super\n",
        "!latex --version"
      ],
      "metadata": {
        "id": "VrswKT4Xg3ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "id": "sM4-FE7Mis3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(metrics.index,metrics[['eval_bleu',\"eval_ter\"]],'--o',label=[\"BLEU\",\"TER\"])\n",
        "plt.plot(metrics2.index,metrics2[['rouge1',\"rouge2\"]],'--*',label=[\"ROUGE-1\",\"ROUGE-2\"])\n",
        "plt.xlabel(r'Epoch', fontsize=20)\n",
        "plt.xlim(-1,21)\n",
        "\n",
        "plt.ylabel(r'Score',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.grid()\n",
        "\n"
      ],
      "metadata": {
        "id": "cyXCVbswfc5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "9e8811ca-53aa-420f-906f-588eb05b68a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = True\n",
        "eval_loss_data.plot(y=[\"eval_loss\"],figsize=(10,5))\n",
        "loss_data.plot(y=[\"loss\"],figsize=(10,5))\n",
        "plt.xlabel(r'Epoch', fontsize=20)\n",
        "plt.ylabel(r'Loss',fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend(fontsize=15,labels=['validation loss',\"train loss\"])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gYtE9oM7oSF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "83a9fc15-84a6-4997-9367-cab4b23d87ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trainer.predict(test_tokenized)\n",
        "predicted_translations=tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
        "\n",
        "actual_translations=tokenizer.batch_decode(test_tokenized['labels'], skip_special_tokens=True)\n",
        "actual_translations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cj-7qdr6kSY_",
        "outputId": "603472a4-b485-41d3-abb5-4e9138eef48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: inputs, targets. If inputs, targets are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 300\n",
            "  Batch size = 32\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['puerta+puerta+puerta',\n",
              " 'yo leer gustar',\n",
              " 'abuelo nuestro',\n",
              " 'mamá tuya médico',\n",
              " 'ustedes tímidos así',\n",
              " 'tú hamburguesa papas comer',\n",
              " 'ayer escuela primo mío ir',\n",
              " 'nosotros oyentes',\n",
              " 'el caminar gustar',\n",
              " 'siempre él contento',\n",
              " 'ellas amables',\n",
              " 'él auto comprar no querer',\n",
              " 'novio mujer tuya oyente',\n",
              " 'parque ahí niño jugar',\n",
              " 'si, yo sordo',\n",
              " 'niño ellos apenados',\n",
              " 'abuelo tuyo desesperado',\n",
              " 'niño ellos masomenos',\n",
              " 'mamá mía masomenos',\n",
              " 'nosotros apenados',\n",
              " 'buenos días, ¿cómo estar tú?',\n",
              " 'maestro mujer gorda',\n",
              " 'México hermano mío vivir',\n",
              " 'amigo nuestro confundido',\n",
              " 'cafetería ahí abuelo mío una galleta comer',\n",
              " 'hola mamá. Buenas tardes',\n",
              " 'entender',\n",
              " 'ustedes ir',\n",
              " 'tú empujar no por favor',\n",
              " '¿papá tuyo vivir dónde?',\n",
              " 'ellos limonada beber',\n",
              " 'México tío mío vivir',\n",
              " 'ustedes español entender',\n",
              " 'pista ahí abuelo correr',\n",
              " 'gato café parece tranquilo',\n",
              " 'ustedes bien',\n",
              " 'nosotros estudiantes',\n",
              " 'él (ella) llorar querer',\n",
              " 'nosotros cerveza beber',\n",
              " '¿ayer tú estudiar?',\n",
              " 'pasado ellos ir',\n",
              " 'perro cl+cl+cl míos asustados',\n",
              " '¿supermercado dónde?',\n",
              " 'desayuno caliente',\n",
              " 'nosotros comer querer',\n",
              " 'abuelo mujer mía pastel chocolate comer',\n",
              " 'tú caminar gustar no',\n",
              " 'gato cl+cl+cl tuyos',\n",
              " 'ustedes hotdog comer',\n",
              " '¿pasado mamá tuya ir dónde?',\n",
              " 'ellos miedosos así',\n",
              " '¿pasado martes tú hacer qué?',\n",
              " 'tío mío artista',\n",
              " 'ventana pocas',\n",
              " 'cafetería ahí novio mujer tuya hamburguesa papas comer',\n",
              " 'tenis míos negros',\n",
              " 'si, ellas sordas',\n",
              " 'foco muchos',\n",
              " 'ayer novio mío revista leer',\n",
              " 'cielo azul',\n",
              " 'hermano mujer tuya arquitecta',\n",
              " 'parque ahí muchos gatos jugar',\n",
              " 'plato ahí peras seis haber',\n",
              " 'nosotros pasear gustar no',\n",
              " '¿pasado jueves tú hacer qué?',\n",
              " 'primo mujer mía estudiante',\n",
              " 'amigo mío masomenos',\n",
              " 'hombre algunos',\n",
              " 'abuelo mío manzana comer',\n",
              " 'nosotros entender no',\n",
              " 'ayer papá mío revista leer',\n",
              " 'nosotros perro adoptar no querer',\n",
              " 'tío tuyo cereal comer',\n",
              " 'amigo tuyo miedoso así',\n",
              " 'papá mío enojado',\n",
              " 'hermano mío lsm aprender querer',\n",
              " 'parque ahí granizar',\n",
              " 'mamá mía lavadora usar',\n",
              " 'plato ahí peras cinco haber',\n",
              " 'hijo mujer',\n",
              " 'foco+foco+foco',\n",
              " 'nosotros reír gustar',\n",
              " 'ayer novio mujer tuya periódico leer',\n",
              " 'hermano mujer mía embarazada',\n",
              " 'tío mío apenado',\n",
              " 'no, tío mío oyente',\n",
              " 'tú español entender no',\n",
              " 'ella abrazo querer',\n",
              " 'abuelo ellos tuyos',\n",
              " 'suegro',\n",
              " 'él inglés aprender querer',\n",
              " 'ellos enojones así',\n",
              " 'hijo mío comer querer',\n",
              " 'sobrino mío lsm aprender querer',\n",
              " 'mamá mía español entender',\n",
              " 'abuelo mío chocolate gustar',\n",
              " 'tío mujer tuya científica',\n",
              " 'abuelo mujer tuya café gustar',\n",
              " 'primo mujer mía suéter gris tener',\n",
              " 'ayer casa ahí él ir',\n",
              " 'abuelo tuyo chocolate gustar no',\n",
              " 'tenis suyos papá mío cafés',\n",
              " '¿amigo tuyo oyente?',\n",
              " 'ellas gentiles',\n",
              " 'ayer nosotros hablar',\n",
              " 'México abuelo mujer mía vivir',\n",
              " 'niño ellos',\n",
              " 'hijo tuyo',\n",
              " 'abuelo tuyo',\n",
              " '¿cómo?',\n",
              " 'sobrino ellos tuyos',\n",
              " 'niño ellos pelota jugar',\n",
              " 'pasado novio mío biblioteca ir',\n",
              " 'yo abrazo querer',\n",
              " 'novio mujer mía sorda',\n",
              " 'ayer amigo mío libro leer',\n",
              " 'primo mujer mía café gustar',\n",
              " 'prima mía amable',\n",
              " 'ellos español entender',\n",
              " 'amigo mujer mía distraída',\n",
              " 'tío tuyo apenado',\n",
              " 'abuelo mío tímido así',\n",
              " 'él masomenos',\n",
              " 'amigo mío abogada',\n",
              " 'nosotros profesores',\n",
              " 'ayer abuelo mujer mío libro leer',\n",
              " 'mesa',\n",
              " 'yo alegre',\n",
              " 'maestro enojado tuyo',\n",
              " 'México novio mujer mía vivir',\n",
              " '¿papá tuyo oyente?',\n",
              " 'azúcar haber no',\n",
              " 'ellas café gustar',\n",
              " 'tío tuyo abogado',\n",
              " 'ustedes enojados',\n",
              " 'novio mío entender',\n",
              " 'tú hacer poder',\n",
              " 'tío mío descansar querer',\n",
              " 'mañana él frances estudiar',\n",
              " 'él (ella) comer querer',\n",
              " 'permiso por favor',\n",
              " 'tú abogado',\n",
              " 'ayer papá tuyo libro leer',\n",
              " 'hermano tuyo galletas comer',\n",
              " 'siempre nosotros contentos',\n",
              " 'ellos chocolate gustar no',\n",
              " 'amigo nuestro miedoso así',\n",
              " 'maestro suyo',\n",
              " 'ayer amigo mujer tuya libro leer',\n",
              " 'yo cerveza beber',\n",
              " 'ustedes ir querer',\n",
              " 'México mamá tuya vivir',\n",
              " 'papá mío café gustar no',\n",
              " 'hermano mujer mía programación aprender querer',\n",
              " 'niño mujer ellas',\n",
              " 'amigo tuyo apenado',\n",
              " 'amigo mujer suya alta',\n",
              " 'papá mío chocolate gustar no',\n",
              " 'ojos azules míos',\n",
              " 'estante ahí un libro haber',\n",
              " 'tío mío lsm aprender querer',\n",
              " 'ustedes inglés aprender querer',\n",
              " 'novio tuyo bien',\n",
              " 'yo ocupado',\n",
              " 'hermano mujer tuya chocolate gustar no',\n",
              " 'ellas sordas',\n",
              " '¿pasado noche tú hacer qué?',\n",
              " 'ustedes ser',\n",
              " 'él feliz así',\n",
              " 'papá mío masomenos',\n",
              " 'papá mío artista',\n",
              " 'tío mujer tuya ingeniera',\n",
              " 'ellos desesperados',\n",
              " 'tú libro leer',\n",
              " 'ayer abuelo mío ocupado',\n",
              " 'hermano mío pollo comer',\n",
              " 'niño mujer ellas distraídas',\n",
              " 'amigo mío alegre',\n",
              " 'próxima semana abuelo mujer mía iglesia ir',\n",
              " 'ayer novio mujer tuya libro leer',\n",
              " 'abuelo mío triste',\n",
              " 'abuelo tuyo',\n",
              " 'tú inglés aprender querer',\n",
              " 'amigo tuyo artista',\n",
              " 'hola niña. Buenas noches',\n",
              " 'mañana yo alemán estudiar',\n",
              " 'yo café caliente gustar',\n",
              " 'novio tuyo mal',\n",
              " 'novio tuyo desesperado',\n",
              " 'tío mujer tuya enojona así',\n",
              " 'casa ahí gato mío peluche jugar',\n",
              " 'yo caminar gustar',\n",
              " 'ella feliz',\n",
              " 'hermano mujer suya',\n",
              " 'hola gustar conocer ellos',\n",
              " 'ustedes médicos',\n",
              " 'siempre él feliz',\n",
              " '¿abuelo mujer vivir dónde?',\n",
              " 'tú pasear gustar',\n",
              " 'ella agradable',\n",
              " '¿futuro noche ellos (ellas) (ustedes) hacer que?',\n",
              " 'calor mucho',\n",
              " 'hermano mujer mía profesora',\n",
              " 'abuelo mujer mía distraída',\n",
              " 'tío mujer tuya desesperada así',\n",
              " 'novio mujer mía oyente',\n",
              " 'si, hermano mujer mía sorda',\n",
              " 'ustedes enojadas',\n",
              " 'ayer ella ocupada',\n",
              " 'casa algunas',\n",
              " 'mamá tuya café gustar',\n",
              " 'primo mujer ellas',\n",
              " 'yo jugomanzana beber',\n",
              " 'primo mujer mía inglés aprender querer',\n",
              " 'pasado amigo tuyo fiesta ir',\n",
              " 'papá mío profesor',\n",
              " 'primo mío ingeniera',\n",
              " 'amigo mujer tuya preocupada',\n",
              " 'papá miedoso así',\n",
              " 'papá mío pasta comer',\n",
              " 'problema haber no',\n",
              " 'ayer novio tuyo libro leer',\n",
              " 'tío mujer mía lsm aprender',\n",
              " 'mamá suya',\n",
              " 'mamá mía tímida así',\n",
              " 'hermano tuyo artista',\n",
              " 'ella café gustar',\n",
              " 'yo artista',\n",
              " 'tío tuyo inglés aprender querer',\n",
              " '¿futuro jueves tú hacer qué?',\n",
              " 'abuelo mío viejo',\n",
              " 'ellos ingenieros',\n",
              " 'novio mío loco',\n",
              " 'primo tuyo médico',\n",
              " 'mamá mía enojada',\n",
              " 'hermano mujer ellas',\n",
              " 'hermano mujer tuya café gustar no',\n",
              " 'novio mío lsm aprender querer',\n",
              " 'yo hombre',\n",
              " 'amigo mujer ellas mías',\n",
              " 'hermano mujer mía pescado comer',\n",
              " 'perro suyo',\n",
              " 'tío mujer nuestra',\n",
              " 'abuelo mujer mía',\n",
              " 'tío mujer mía lsm aprender querer',\n",
              " 'niño ellos jovenes así',\n",
              " 'amigo mujer mía lsm entender no',\n",
              " 'no, papá mío oyente',\n",
              " 'próxima semana amigo mío universidad ir',\n",
              " 'él chocolate gustar',\n",
              " 'ellas español aprender querer',\n",
              " 'yo lsm entender',\n",
              " 'hombre ellos',\n",
              " 'eso yo hacer poder no',\n",
              " 'comida servida',\n",
              " 'esposo algunos',\n",
              " 'novio mío triste',\n",
              " 'primo mujer mía embarazada',\n",
              " '¿tío tuyo oyente?',\n",
              " 'hombre ellos',\n",
              " 'nosotros descansar querer',\n",
              " 'niño mujer ellas bien',\n",
              " 'abuelo mujer mía cacerola arroz cocinar',\n",
              " 'pasado novio mujer mía biblioteca ir',\n",
              " 'hermano mujer mía sorda',\n",
              " 'tío mujer mía distraída así',\n",
              " 'clima frío',\n",
              " 'ellos confundidos',\n",
              " 'ella loca',\n",
              " 'ellas lsm aprender',\n",
              " 'tío mujer mía abogada',\n",
              " 'ellas arquitectas',\n",
              " 'mujer muchas',\n",
              " 'tú ser',\n",
              " 'ayer yo huevos comer',\n",
              " 'ayer ellos (as) libro leer',\n",
              " 'gato tuyo',\n",
              " 'tú loco',\n",
              " 'hermano mío triste',\n",
              " 'ayer primo mujer mía libro leer',\n",
              " 'tú leer gustar no',\n",
              " 'ustedes miedosos así',\n",
              " 'semana pasada éleso hacer',\n",
              " 'manzana roja',\n",
              " 'pista ahí él (ella) correr querer',\n",
              " 'tú sonreír gustar',\n",
              " 'nosotros',\n",
              " 'suegro mujer ellas',\n",
              " 'niño mujer ellas enojonas así',\n",
              " 'ellos caminar gustar no',\n",
              " 'ustedes café gustar no',\n",
              " 'día caluroso',\n",
              " 'lunes a viernes nosotros trabajar',\n",
              " 'mujer enojada',\n",
              " 'novio mujer mía masomenos',\n",
              " 'ella cerveza beber',\n",
              " 'niño mujer ellas estudiar',\n",
              " 'cafetería tío tuyo café beber',\n",
              " 'tío tuyo chocolate gustar',\n",
              " 'biblioteca ahí sobrino mujer estudiar']"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(predicted, actual) in enumerate(zip(predicted_translations,actual_translations)):\n",
        "    print(f\"Example {i + 1}:\")\n",
        "    print(f\"Predicted: {predicted}\")\n",
        "    print(f\"Actual: {actual}\")\n",
        "    print(\"-\" * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jt-bNrGmaSi",
        "outputId": "4dbd3068-9a0d-43de-c34c-004996d8ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Predicted: puerta +puerta+puerta\n",
            "Actual: puerta+puerta+puerta\n",
            "--------------------\n",
            "Example 2:\n",
            "Predicted: yo leer gustar\n",
            "Actual: yo leer gustar\n",
            "--------------------\n",
            "Example 3:\n",
            "Predicted: abuelo nuestro\n",
            "Actual: abuelo nuestro\n",
            "--------------------\n",
            "Example 4:\n",
            "Predicted: mamá tuya médico\n",
            "Actual: mamá tuya médico\n",
            "--------------------\n",
            "Example 5:\n",
            "Predicted: ustedes tímidos así\n",
            "Actual: ustedes tímidos así\n",
            "--------------------\n",
            "Example 6:\n",
            "Predicted: tú hamburguesa papas comer\n",
            "Actual: tú hamburguesa papas comer\n",
            "--------------------\n",
            "Example 7:\n",
            "Predicted: ayer primo mío escuela ir\n",
            "Actual: ayer escuela primo mío ir\n",
            "--------------------\n",
            "Example 8:\n",
            "Predicted: nosotros oyentes\n",
            "Actual: nosotros oyentes\n",
            "--------------------\n",
            "Example 9:\n",
            "Predicted: ella caminar gustar\n",
            "Actual: el caminar gustar\n",
            "--------------------\n",
            "Example 10:\n",
            "Predicted: siempre el contento\n",
            "Actual: siempre él contento\n",
            "--------------------\n",
            "Example 11:\n",
            "Predicted: ellas amables\n",
            "Actual: ellas amables\n",
            "--------------------\n",
            "Example 12:\n",
            "Predicted: él auto comprar no querer\n",
            "Actual: él auto comprar no querer\n",
            "--------------------\n",
            "Example 13:\n",
            "Predicted: novio mujer tuya oyente\n",
            "Actual: novio mujer tuya oyente\n",
            "--------------------\n",
            "Example 14:\n",
            "Predicted: parque ahí niño jugar\n",
            "Actual: parque ahí niño jugar\n",
            "--------------------\n",
            "Example 15:\n",
            "Predicted: si, yo sordo\n",
            "Actual: si, yo sordo\n",
            "--------------------\n",
            "Example 16:\n",
            "Predicted: niño ellos apenados\n",
            "Actual: niño ellos apenados\n",
            "--------------------\n",
            "Example 17:\n",
            "Predicted: abuelo tuyo desesperado así\n",
            "Actual: abuelo tuyo desesperado\n",
            "--------------------\n",
            "Example 18:\n",
            "Predicted: niño ellos masomenos\n",
            "Actual: niño ellos masomenos\n",
            "--------------------\n",
            "Example 19:\n",
            "Predicted: mamá mía masomenos\n",
            "Actual: mamá mía masomenos\n",
            "--------------------\n",
            "Example 20:\n",
            "Predicted: nosotros apenados\n",
            "Actual: nosotros apenados\n",
            "--------------------\n",
            "Example 21:\n",
            "Predicted: buenos días, ¿cómo estar tú?\n",
            "Actual: buenos días, ¿cómo estar tú?\n",
            "--------------------\n",
            "Example 22:\n",
            "Predicted: maestro mujer gorda\n",
            "Actual: maestro mujer gorda\n",
            "--------------------\n",
            "Example 23:\n",
            "Predicted: México hermano mío vivir\n",
            "Actual: México hermano mío vivir\n",
            "--------------------\n",
            "Example 24:\n",
            "Predicted: amigo nuestro confundido\n",
            "Actual: amigo nuestro confundido\n",
            "--------------------\n",
            "Example 25:\n",
            "Predicted: cafetería ahí abuelo mío galleta comer\n",
            "Actual: cafetería ahí abuelo mío una galleta comer\n",
            "--------------------\n",
            "Example 26:\n",
            "Predicted: hola mamá. Buenas tardes\n",
            "Actual: hola mamá. Buenas tardes\n",
            "--------------------\n",
            "Example 27:\n",
            "Predicted: yo entender\n",
            "Actual: entender\n",
            "--------------------\n",
            "Example 28:\n",
            "Predicted: váyanse\n",
            "Actual: ustedes ir\n",
            "--------------------\n",
            "Example 29:\n",
            "Predicted: tú empujes por favor no\n",
            "Actual: tú empujar no por favor\n",
            "--------------------\n",
            "Example 30:\n",
            "Predicted: ¿papá tuyo vivir dónde?\n",
            "Actual: ¿papá tuyo vivir dónde?\n",
            "--------------------\n",
            "Example 31:\n",
            "Predicted: ellos limonada beber\n",
            "Actual: ellos limonada beber\n",
            "--------------------\n",
            "Example 32:\n",
            "Predicted: México tío mío vivir\n",
            "Actual: México tío mío vivir\n",
            "--------------------\n",
            "Example 33:\n",
            "Predicted: ustedes español entender\n",
            "Actual: ustedes español entender\n",
            "--------------------\n",
            "Example 34:\n",
            "Predicted: pista ahí abuelo mío correr\n",
            "Actual: pista ahí abuelo correr\n",
            "--------------------\n",
            "Example 35:\n",
            "Predicted: gato café tranquilo\n",
            "Actual: gato café parece tranquilo\n",
            "--------------------\n",
            "Example 36:\n",
            "Predicted: ustedes bien\n",
            "Actual: ustedes bien\n",
            "--------------------\n",
            "Example 37:\n",
            "Predicted: nosotros estudiantes\n",
            "Actual: nosotros estudiantes\n",
            "--------------------\n",
            "Example 38:\n",
            "Predicted: él (ella) llorar querer\n",
            "Actual: él (ella) llorar querer\n",
            "--------------------\n",
            "Example 39:\n",
            "Predicted: nosotros cerveza beber\n",
            "Actual: nosotros cerveza beber\n",
            "--------------------\n",
            "Example 40:\n",
            "Predicted: ¿ayer tú estudiar?\n",
            "Actual: ¿ayer tú estudiar?\n",
            "--------------------\n",
            "Example 41:\n",
            "Predicted: pasado ustedes ir\n",
            "Actual: pasado ellos ir\n",
            "--------------------\n",
            "Example 42:\n",
            "Predicted: perro cl+cl+cl míos asustados\n",
            "Actual: perro cl+cl+cl míos asustados\n",
            "--------------------\n",
            "Example 43:\n",
            "Predicted: ¿próximo supermercado dónde?\n",
            "Actual: ¿supermercado dónde?\n",
            "--------------------\n",
            "Example 44:\n",
            "Predicted: desayuno caliente\n",
            "Actual: desayuno caliente\n",
            "--------------------\n",
            "Example 45:\n",
            "Predicted: nosotros comer querer\n",
            "Actual: nosotros comer querer\n",
            "--------------------\n",
            "Example 46:\n",
            "Predicted: abuelo mujer mía pastel chocolate comer\n",
            "Actual: abuelo mujer mía pastel chocolate comer\n",
            "--------------------\n",
            "Example 47:\n",
            "Predicted: tú caminar gustar no\n",
            "Actual: tú caminar gustar no\n",
            "--------------------\n",
            "Example 48:\n",
            "Predicted: gato cl+cl+cl tuyos\n",
            "Actual: gato cl+cl+cl tuyos\n",
            "--------------------\n",
            "Example 49:\n",
            "Predicted: ustedes hotdog comer\n",
            "Actual: ustedes hotdog comer\n",
            "--------------------\n",
            "Example 50:\n",
            "Predicted: ¿pasado mamá tuya ir dónde?\n",
            "Actual: ¿pasado mamá tuya ir dónde?\n",
            "--------------------\n",
            "Example 51:\n",
            "Predicted: ellos miedosos así\n",
            "Actual: ellos miedosos así\n",
            "--------------------\n",
            "Example 52:\n",
            "Predicted: ¿martes tú hacer qué?\n",
            "Actual: ¿pasado martes tú hacer qué?\n",
            "--------------------\n",
            "Example 53:\n",
            "Predicted: tío mío artista\n",
            "Actual: tío mío artista\n",
            "--------------------\n",
            "Example 54:\n",
            "Predicted: ventana pocas\n",
            "Actual: ventana pocas\n",
            "--------------------\n",
            "Example 55:\n",
            "Predicted: cafetería ahí novio mujer tuya hamburguesa papas comer\n",
            "Actual: cafetería ahí novio mujer tuya hamburguesa papas comer\n",
            "--------------------\n",
            "Example 56:\n",
            "Predicted: tenis míos negros\n",
            "Actual: tenis míos negros\n",
            "--------------------\n",
            "Example 57:\n",
            "Predicted: si, ellas sordas\n",
            "Actual: si, ellas sordas\n",
            "--------------------\n",
            "Example 58:\n",
            "Predicted: foco muchos\n",
            "Actual: foco muchos\n",
            "--------------------\n",
            "Example 59:\n",
            "Predicted: ayer novio mío revista leer\n",
            "Actual: ayer novio mío revista leer\n",
            "--------------------\n",
            "Example 60:\n",
            "Predicted: cielo azul\n",
            "Actual: cielo azul\n",
            "--------------------\n",
            "Example 61:\n",
            "Predicted: hermano mujer tuya arquitecta\n",
            "Actual: hermano mujer tuya arquitecta\n",
            "--------------------\n",
            "Example 62:\n",
            "Predicted: parque ahí muchos gatos jugar\n",
            "Actual: parque ahí muchos gatos jugar\n",
            "--------------------\n",
            "Example 63:\n",
            "Predicted: plato ahí peras seis haber\n",
            "Actual: plato ahí peras seis haber\n",
            "--------------------\n",
            "Example 64:\n",
            "Predicted: nosotros pasear gustar no\n",
            "Actual: nosotros pasear gustar no\n",
            "--------------------\n",
            "Example 65:\n",
            "Predicted: ¿pasado jueves tú hacer qué?\n",
            "Actual: ¿pasado jueves tú hacer qué?\n",
            "--------------------\n",
            "Example 66:\n",
            "Predicted: primo mujer mía estudiante\n",
            "Actual: primo mujer mía estudiante\n",
            "--------------------\n",
            "Example 67:\n",
            "Predicted: amigo mío masomenos\n",
            "Actual: amigo mío masomenos\n",
            "--------------------\n",
            "Example 68:\n",
            "Predicted: hombre algunos\n",
            "Actual: hombre algunos\n",
            "--------------------\n",
            "Example 69:\n",
            "Predicted: abuelo mío manzana comer\n",
            "Actual: abuelo mío manzana comer\n",
            "--------------------\n",
            "Example 70:\n",
            "Predicted: nosotros entender no\n",
            "Actual: nosotros entender no\n",
            "--------------------\n",
            "Example 71:\n",
            "Predicted: ayer papá mío revista leer\n",
            "Actual: ayer papá mío revista leer\n",
            "--------------------\n",
            "Example 72:\n",
            "Predicted: nosotros perro adoptar no querer\n",
            "Actual: nosotros perro adoptar no querer\n",
            "--------------------\n",
            "Example 73:\n",
            "Predicted: tío tuyo cereal comer\n",
            "Actual: tío tuyo cereal comer\n",
            "--------------------\n",
            "Example 74:\n",
            "Predicted: amigo tuyo miedoso así\n",
            "Actual: amigo tuyo miedoso así\n",
            "--------------------\n",
            "Example 75:\n",
            "Predicted: papá mío enojado\n",
            "Actual: papá mío enojado\n",
            "--------------------\n",
            "Example 76:\n",
            "Predicted: hermano mío lsm aprender querer\n",
            "Actual: hermano mío lsm aprender querer\n",
            "--------------------\n",
            "Example 77:\n",
            "Predicted: parque ahí mucha gente granizando\n",
            "Actual: parque ahí granizar\n",
            "--------------------\n",
            "Example 78:\n",
            "Predicted: mamá mía lavadora usar\n",
            "Actual: mamá mía lavadora usar\n",
            "--------------------\n",
            "Example 79:\n",
            "Predicted: plato ahí peras cinco haber\n",
            "Actual: plato ahí peras cinco haber\n",
            "--------------------\n",
            "Example 80:\n",
            "Predicted: hijo mujer\n",
            "Actual: hijo mujer\n",
            "--------------------\n",
            "Example 81:\n",
            "Predicted: foco+foco\n",
            "Actual: foco+foco+foco\n",
            "--------------------\n",
            "Example 82:\n",
            "Predicted: nosotros reír gustar\n",
            "Actual: nosotros reír gustar\n",
            "--------------------\n",
            "Example 83:\n",
            "Predicted: ayer novio mujer tuya periódico leer\n",
            "Actual: ayer novio mujer tuya periódico leer\n",
            "--------------------\n",
            "Example 84:\n",
            "Predicted: hermano mujer mía embarazada\n",
            "Actual: hermano mujer mía embarazada\n",
            "--------------------\n",
            "Example 85:\n",
            "Predicted: tío mío apenado\n",
            "Actual: tío mío apenado\n",
            "--------------------\n",
            "Example 86:\n",
            "Predicted: no, tío mío oyente\n",
            "Actual: no, tío mío oyente\n",
            "--------------------\n",
            "Example 87:\n",
            "Predicted: tú español entender no\n",
            "Actual: tú español entender no\n",
            "--------------------\n",
            "Example 88:\n",
            "Predicted: ella abrazo querer\n",
            "Actual: ella abrazo querer\n",
            "--------------------\n",
            "Example 89:\n",
            "Predicted: abuelo ellos tuyos\n",
            "Actual: abuelo ellos tuyos\n",
            "--------------------\n",
            "Example 90:\n",
            "Predicted: suegro\n",
            "Actual: suegro\n",
            "--------------------\n",
            "Example 91:\n",
            "Predicted: él (ella) inglés aprender querer\n",
            "Actual: él inglés aprender querer\n",
            "--------------------\n",
            "Example 92:\n",
            "Predicted: ellos enojones así\n",
            "Actual: ellos enojones así\n",
            "--------------------\n",
            "Example 93:\n",
            "Predicted: hijo mío comer querer\n",
            "Actual: hijo mío comer querer\n",
            "--------------------\n",
            "Example 94:\n",
            "Predicted: sobrino mío lsm aprender querer\n",
            "Actual: sobrino mío lsm aprender querer\n",
            "--------------------\n",
            "Example 95:\n",
            "Predicted: mamá mía español entender\n",
            "Actual: mamá mía español entender\n",
            "--------------------\n",
            "Example 96:\n",
            "Predicted: abuelo mío chocolate gustar\n",
            "Actual: abuelo mío chocolate gustar\n",
            "--------------------\n",
            "Example 97:\n",
            "Predicted: tío mujer tuya científica\n",
            "Actual: tío mujer tuya científica\n",
            "--------------------\n",
            "Example 98:\n",
            "Predicted: abuelo mujer tuya café gustar\n",
            "Actual: abuelo mujer tuya café gustar\n",
            "--------------------\n",
            "Example 99:\n",
            "Predicted: primo mujer mía suéter gris tener\n",
            "Actual: primo mujer mía suéter gris tener\n",
            "--------------------\n",
            "Example 100:\n",
            "Predicted: ayer él casa ir\n",
            "Actual: ayer casa ahí él ir\n",
            "--------------------\n",
            "Example 101:\n",
            "Predicted: abuelo tuyo chocolate gustar no\n",
            "Actual: abuelo tuyo chocolate gustar no\n",
            "--------------------\n",
            "Example 102:\n",
            "Predicted: tenis suyos papá míos cafés\n",
            "Actual: tenis suyos papá mío cafés\n",
            "--------------------\n",
            "Example 103:\n",
            "Predicted: ¿amigo tuyo oyente?\n",
            "Actual: ¿amigo tuyo oyente?\n",
            "--------------------\n",
            "Example 104:\n",
            "Predicted: ellas gentiles\n",
            "Actual: ellas gentiles\n",
            "--------------------\n",
            "Example 105:\n",
            "Predicted: ayer nosotros hablar\n",
            "Actual: ayer nosotros hablar\n",
            "--------------------\n",
            "Example 106:\n",
            "Predicted: México abuelo mujer mía vivir\n",
            "Actual: México abuelo mujer mía vivir\n",
            "--------------------\n",
            "Example 107:\n",
            "Predicted: niño ellos\n",
            "Actual: niño ellos\n",
            "--------------------\n",
            "Example 108:\n",
            "Predicted: hijo tuyo\n",
            "Actual: hijo tuyo\n",
            "--------------------\n",
            "Example 109:\n",
            "Predicted: abuelo tuyo\n",
            "Actual: abuelo tuyo\n",
            "--------------------\n",
            "Example 110:\n",
            "Predicted: ¿cómo?\n",
            "Actual: ¿cómo?\n",
            "--------------------\n",
            "Example 111:\n",
            "Predicted: sobrino ellos tuyos\n",
            "Actual: sobrino ellos tuyos\n",
            "--------------------\n",
            "Example 112:\n",
            "Predicted: niño ellos pelota jugar\n",
            "Actual: niño ellos pelota jugar\n",
            "--------------------\n",
            "Example 113:\n",
            "Predicted: pasado novio mío biblioteca ir\n",
            "Actual: pasado novio mío biblioteca ir\n",
            "--------------------\n",
            "Example 114:\n",
            "Predicted: yo abrazo querer\n",
            "Actual: yo abrazo querer\n",
            "--------------------\n",
            "Example 115:\n",
            "Predicted: novio mujer mía sorda\n",
            "Actual: novio mujer mía sorda\n",
            "--------------------\n",
            "Example 116:\n",
            "Predicted: ayer amigo mío libro leer\n",
            "Actual: ayer amigo mío libro leer\n",
            "--------------------\n",
            "Example 117:\n",
            "Predicted: primo mujer mía café gustar\n",
            "Actual: primo mujer mía café gustar\n",
            "--------------------\n",
            "Example 118:\n",
            "Predicted: primo mujer mía amable\n",
            "Actual: prima mía amable\n",
            "--------------------\n",
            "Example 119:\n",
            "Predicted: ellos español entender\n",
            "Actual: ellos español entender\n",
            "--------------------\n",
            "Example 120:\n",
            "Predicted: amigo mujer mía distraída\n",
            "Actual: amigo mujer mía distraída\n",
            "--------------------\n",
            "Example 121:\n",
            "Predicted: tío tuyo apenado\n",
            "Actual: tío tuyo apenado\n",
            "--------------------\n",
            "Example 122:\n",
            "Predicted: abuelo mío tímido así\n",
            "Actual: abuelo mío tímido así\n",
            "--------------------\n",
            "Example 123:\n",
            "Predicted: él masomenos\n",
            "Actual: él masomenos\n",
            "--------------------\n",
            "Example 124:\n",
            "Predicted: amigo mío abogada\n",
            "Actual: amigo mío abogada\n",
            "--------------------\n",
            "Example 125:\n",
            "Predicted: nosotros profesores\n",
            "Actual: nosotros profesores\n",
            "--------------------\n",
            "Example 126:\n",
            "Predicted: ayer abuelo mujer mío libro leer\n",
            "Actual: ayer abuelo mujer mío libro leer\n",
            "--------------------\n",
            "Example 127:\n",
            "Predicted: mesa\n",
            "Actual: mesa\n",
            "--------------------\n",
            "Example 128:\n",
            "Predicted: yo alegre\n",
            "Actual: yo alegre\n",
            "--------------------\n",
            "Example 129:\n",
            "Predicted: maestro tuyo enojado\n",
            "Actual: maestro enojado tuyo\n",
            "--------------------\n",
            "Example 130:\n",
            "Predicted: México novio mujer mía vivir\n",
            "Actual: México novio mujer mía vivir\n",
            "--------------------\n",
            "Example 131:\n",
            "Predicted: ¿papá tuyo oyente?\n",
            "Actual: ¿papá tuyo oyente?\n",
            "--------------------\n",
            "Example 132:\n",
            "Predicted: azúcar haber no\n",
            "Actual: azúcar haber no\n",
            "--------------------\n",
            "Example 133:\n",
            "Predicted: ellos café gustar\n",
            "Actual: ellas café gustar\n",
            "--------------------\n",
            "Example 134:\n",
            "Predicted: tío tuyo abogado\n",
            "Actual: tío tuyo abogado\n",
            "--------------------\n",
            "Example 135:\n",
            "Predicted: ustedes enojados\n",
            "Actual: ustedes enojados\n",
            "--------------------\n",
            "Example 136:\n",
            "Predicted: novio mío entender\n",
            "Actual: novio mío entender\n",
            "--------------------\n",
            "Example 137:\n",
            "Predicted: tú hacer poder\n",
            "Actual: tú hacer poder\n",
            "--------------------\n",
            "Example 138:\n",
            "Predicted: tío mío descansar querer\n",
            "Actual: tío mío descansar querer\n",
            "--------------------\n",
            "Example 139:\n",
            "Predicted: mañana él frances estudiar\n",
            "Actual: mañana él frances estudiar\n",
            "--------------------\n",
            "Example 140:\n",
            "Predicted: él (ella) comer querer\n",
            "Actual: él (ella) comer querer\n",
            "--------------------\n",
            "Example 141:\n",
            "Predicted: permiso por favor\n",
            "Actual: permiso por favor\n",
            "--------------------\n",
            "Example 142:\n",
            "Predicted: tú abogado\n",
            "Actual: tú abogado\n",
            "--------------------\n",
            "Example 143:\n",
            "Predicted: ayer papá tuyo libro leer\n",
            "Actual: ayer papá tuyo libro leer\n",
            "--------------------\n",
            "Example 144:\n",
            "Predicted: hermano tuyo galletas comer\n",
            "Actual: hermano tuyo galletas comer\n",
            "--------------------\n",
            "Example 145:\n",
            "Predicted: siempre nosotros contentos\n",
            "Actual: siempre nosotros contentos\n",
            "--------------------\n",
            "Example 146:\n",
            "Predicted: ellos chocolate gustar no\n",
            "Actual: ellos chocolate gustar no\n",
            "--------------------\n",
            "Example 147:\n",
            "Predicted: amigo nuestro miedoso así\n",
            "Actual: amigo nuestro miedoso así\n",
            "--------------------\n",
            "Example 148:\n",
            "Predicted: maestro suyo\n",
            "Actual: maestro suyo\n",
            "--------------------\n",
            "Example 149:\n",
            "Predicted: ayer amigo mujer tuya libro leer\n",
            "Actual: ayer amigo mujer tuya libro leer\n",
            "--------------------\n",
            "Example 150:\n",
            "Predicted: yo cerveza beber\n",
            "Actual: yo cerveza beber\n",
            "--------------------\n",
            "Example 151:\n",
            "Predicted: ellos (as)/ustedes ir querer\n",
            "Actual: ustedes ir querer\n",
            "--------------------\n",
            "Example 152:\n",
            "Predicted: México mamá tuya vivir\n",
            "Actual: México mamá tuya vivir\n",
            "--------------------\n",
            "Example 153:\n",
            "Predicted: papá mío café gustar no\n",
            "Actual: papá mío café gustar no\n",
            "--------------------\n",
            "Example 154:\n",
            "Predicted: hermano mujer mía programación aprender querer\n",
            "Actual: hermano mujer mía programación aprender querer\n",
            "--------------------\n",
            "Example 155:\n",
            "Predicted: niño mujer ellas\n",
            "Actual: niño mujer ellas\n",
            "--------------------\n",
            "Example 156:\n",
            "Predicted: amigo tuyo apenado\n",
            "Actual: amigo tuyo apenado\n",
            "--------------------\n",
            "Example 157:\n",
            "Predicted: amigo mujer alta\n",
            "Actual: amigo mujer suya alta\n",
            "--------------------\n",
            "Example 158:\n",
            "Predicted: papá mío chocolate gustar no\n",
            "Actual: papá mío chocolate gustar no\n",
            "--------------------\n",
            "Example 159:\n",
            "Predicted: ojos míos azules\n",
            "Actual: ojos azules míos\n",
            "--------------------\n",
            "Example 160:\n",
            "Predicted: estante ahí libro haber\n",
            "Actual: estante ahí un libro haber\n",
            "--------------------\n",
            "Example 161:\n",
            "Predicted: tío mío lsm aprender querer\n",
            "Actual: tío mío lsm aprender querer\n",
            "--------------------\n",
            "Example 162:\n",
            "Predicted: ustedes inglés aprender querer\n",
            "Actual: ustedes inglés aprender querer\n",
            "--------------------\n",
            "Example 163:\n",
            "Predicted: novio tuyo bien\n",
            "Actual: novio tuyo bien\n",
            "--------------------\n",
            "Example 164:\n",
            "Predicted: yo ocupado\n",
            "Actual: yo ocupado\n",
            "--------------------\n",
            "Example 165:\n",
            "Predicted: hermano mujer tuya chocolate gustar no\n",
            "Actual: hermano mujer tuya chocolate gustar no\n",
            "--------------------\n",
            "Example 166:\n",
            "Predicted: ellas sordas\n",
            "Actual: ellas sordas\n",
            "--------------------\n",
            "Example 167:\n",
            "Predicted: ¿pasado tarde tú hacer que?\n",
            "Actual: ¿pasado noche tú hacer qué?\n",
            "--------------------\n",
            "Example 168:\n",
            "Predicted: ellos ser\n",
            "Actual: ustedes ser\n",
            "--------------------\n",
            "Example 169:\n",
            "Predicted: él feliz así\n",
            "Actual: él feliz así\n",
            "--------------------\n",
            "Example 170:\n",
            "Predicted: papá mío masomenos\n",
            "Actual: papá mío masomenos\n",
            "--------------------\n",
            "Example 171:\n",
            "Predicted: papá mío artista\n",
            "Actual: papá mío artista\n",
            "--------------------\n",
            "Example 172:\n",
            "Predicted: tío mujer tuya ingeniera\n",
            "Actual: tío mujer tuya ingeniera\n",
            "--------------------\n",
            "Example 173:\n",
            "Predicted: ellos (as) (ustedes) desesperados\n",
            "Actual: ellos desesperados\n",
            "--------------------\n",
            "Example 174:\n",
            "Predicted: tú libro leer\n",
            "Actual: tú libro leer\n",
            "--------------------\n",
            "Example 175:\n",
            "Predicted: ayer abuelo mío ocupado\n",
            "Actual: ayer abuelo mío ocupado\n",
            "--------------------\n",
            "Example 176:\n",
            "Predicted: hermano mío pollo comer\n",
            "Actual: hermano mío pollo comer\n",
            "--------------------\n",
            "Example 177:\n",
            "Predicted: niño mujer ellas distraídas\n",
            "Actual: niño mujer ellas distraídas\n",
            "--------------------\n",
            "Example 178:\n",
            "Predicted: amigo mío alegre\n",
            "Actual: amigo mío alegre\n",
            "--------------------\n",
            "Example 179:\n",
            "Predicted: próxima semana abuelo mujer mía iglesia ir\n",
            "Actual: próxima semana abuelo mujer mía iglesia ir\n",
            "--------------------\n",
            "Example 180:\n",
            "Predicted: ayer novio mujer tuya libro leer\n",
            "Actual: ayer novio mujer tuya libro leer\n",
            "--------------------\n",
            "Example 181:\n",
            "Predicted: abuelo mío triste\n",
            "Actual: abuelo mío triste\n",
            "--------------------\n",
            "Example 182:\n",
            "Predicted: abuelo tuyo\n",
            "Actual: abuelo tuyo\n",
            "--------------------\n",
            "Example 183:\n",
            "Predicted: tú inglés aprender querer\n",
            "Actual: tú inglés aprender querer\n",
            "--------------------\n",
            "Example 184:\n",
            "Predicted: amigo tuyo artista\n",
            "Actual: amigo tuyo artista\n",
            "--------------------\n",
            "Example 185:\n",
            "Predicted: hola niña. Buenas noches\n",
            "Actual: hola niña. Buenas noches\n",
            "--------------------\n",
            "Example 186:\n",
            "Predicted: mañana yo alemán estudiar\n",
            "Actual: mañana yo alemán estudiar\n",
            "--------------------\n",
            "Example 187:\n",
            "Predicted: yo café caliente gustar\n",
            "Actual: yo café caliente gustar\n",
            "--------------------\n",
            "Example 188:\n",
            "Predicted: novio tuyo mal\n",
            "Actual: novio tuyo mal\n",
            "--------------------\n",
            "Example 189:\n",
            "Predicted: novio tuyo desesperado así\n",
            "Actual: novio tuyo desesperado\n",
            "--------------------\n",
            "Example 190:\n",
            "Predicted: tío mujer tuya enojona así\n",
            "Actual: tío mujer tuya enojona así\n",
            "--------------------\n",
            "Example 191:\n",
            "Predicted: casa ahí gato mío peluche jugar\n",
            "Actual: casa ahí gato mío peluche jugar\n",
            "--------------------\n",
            "Example 192:\n",
            "Predicted: yo caminar gustar\n",
            "Actual: yo caminar gustar\n",
            "--------------------\n",
            "Example 193:\n",
            "Predicted: ella feliz\n",
            "Actual: ella feliz\n",
            "--------------------\n",
            "Example 194:\n",
            "Predicted: hermano mujer suya\n",
            "Actual: hermano mujer suya\n",
            "--------------------\n",
            "Example 195:\n",
            "Predicted: hola gustar conocer ustedes\n",
            "Actual: hola gustar conocer ellos\n",
            "--------------------\n",
            "Example 196:\n",
            "Predicted: ustedes médicos\n",
            "Actual: ustedes médicos\n",
            "--------------------\n",
            "Example 197:\n",
            "Predicted: siempre el feliz\n",
            "Actual: siempre él feliz\n",
            "--------------------\n",
            "Example 198:\n",
            "Predicted: ¿abuelo mujer tuya vivir dónde?\n",
            "Actual: ¿abuelo mujer vivir dónde?\n",
            "--------------------\n",
            "Example 199:\n",
            "Predicted: tú pasear gustar\n",
            "Actual: tú pasear gustar\n",
            "--------------------\n",
            "Example 200:\n",
            "Predicted: ella agradable\n",
            "Actual: ella agradable\n",
            "--------------------\n",
            "Example 201:\n",
            "Predicted: ¿futuro noche ellos (ellas) (ustedes) hacer qué?\n",
            "Actual: ¿futuro noche ellos (ellas) (ustedes) hacer que?\n",
            "--------------------\n",
            "Example 202:\n",
            "Predicted: calor mucho\n",
            "Actual: calor mucho\n",
            "--------------------\n",
            "Example 203:\n",
            "Predicted: hermano mujer mía profesora\n",
            "Actual: hermano mujer mía profesora\n",
            "--------------------\n",
            "Example 204:\n",
            "Predicted: abuelo mujer mía distraída\n",
            "Actual: abuelo mujer mía distraída\n",
            "--------------------\n",
            "Example 205:\n",
            "Predicted: tío mujer tuya desesperada así\n",
            "Actual: tío mujer tuya desesperada así\n",
            "--------------------\n",
            "Example 206:\n",
            "Predicted: novio mujer mía oyente\n",
            "Actual: novio mujer mía oyente\n",
            "--------------------\n",
            "Example 207:\n",
            "Predicted: si, hermano mujer mía sorda\n",
            "Actual: si, hermano mujer mía sorda\n",
            "--------------------\n",
            "Example 208:\n",
            "Predicted: ustedes enojadas\n",
            "Actual: ustedes enojadas\n",
            "--------------------\n",
            "Example 209:\n",
            "Predicted: ayer ella ocupada\n",
            "Actual: ayer ella ocupada\n",
            "--------------------\n",
            "Example 210:\n",
            "Predicted: casa algunas\n",
            "Actual: casa algunas\n",
            "--------------------\n",
            "Example 211:\n",
            "Predicted: mamá tuya café gustar\n",
            "Actual: mamá tuya café gustar\n",
            "--------------------\n",
            "Example 212:\n",
            "Predicted: primo mujer ellas\n",
            "Actual: primo mujer ellas\n",
            "--------------------\n",
            "Example 213:\n",
            "Predicted: yo jugo manzana beber\n",
            "Actual: yo jugomanzana beber\n",
            "--------------------\n",
            "Example 214:\n",
            "Predicted: primo mujer mía inglés aprender querer\n",
            "Actual: primo mujer mía inglés aprender querer\n",
            "--------------------\n",
            "Example 215:\n",
            "Predicted: pasado amigo tuyo fiesta ir\n",
            "Actual: pasado amigo tuyo fiesta ir\n",
            "--------------------\n",
            "Example 216:\n",
            "Predicted: papá mío profesor\n",
            "Actual: papá mío profesor\n",
            "--------------------\n",
            "Example 217:\n",
            "Predicted: primo mío ingeniera\n",
            "Actual: primo mío ingeniera\n",
            "--------------------\n",
            "Example 218:\n",
            "Predicted: amigo mujer tuya preocupada\n",
            "Actual: amigo mujer tuya preocupada\n",
            "--------------------\n",
            "Example 219:\n",
            "Predicted: papá mío miedoso así\n",
            "Actual: papá miedoso así\n",
            "--------------------\n",
            "Example 220:\n",
            "Predicted: papá mío pasta comer\n",
            "Actual: papá mío pasta comer\n",
            "--------------------\n",
            "Example 221:\n",
            "Predicted: problema haber no\n",
            "Actual: problema haber no\n",
            "--------------------\n",
            "Example 222:\n",
            "Predicted: ayer novio tuyo libro leer\n",
            "Actual: ayer novio tuyo libro leer\n",
            "--------------------\n",
            "Example 223:\n",
            "Predicted: tío mujer mía lsm aprender\n",
            "Actual: tío mujer mía lsm aprender\n",
            "--------------------\n",
            "Example 224:\n",
            "Predicted: mamá suya\n",
            "Actual: mamá suya\n",
            "--------------------\n",
            "Example 225:\n",
            "Predicted: mamá mía tímida así\n",
            "Actual: mamá mía tímida así\n",
            "--------------------\n",
            "Example 226:\n",
            "Predicted: hermano tuyo artista\n",
            "Actual: hermano tuyo artista\n",
            "--------------------\n",
            "Example 227:\n",
            "Predicted: ella café gustar\n",
            "Actual: ella café gustar\n",
            "--------------------\n",
            "Example 228:\n",
            "Predicted: yo artista\n",
            "Actual: yo artista\n",
            "--------------------\n",
            "Example 229:\n",
            "Predicted: tío tuyo inglés aprender querer\n",
            "Actual: tío tuyo inglés aprender querer\n",
            "--------------------\n",
            "Example 230:\n",
            "Predicted: ¿próximo jueves tú hacer qué?\n",
            "Actual: ¿futuro jueves tú hacer qué?\n",
            "--------------------\n",
            "Example 231:\n",
            "Predicted: abuelo mío viejo\n",
            "Actual: abuelo mío viejo\n",
            "--------------------\n",
            "Example 232:\n",
            "Predicted: ellos ingenieros\n",
            "Actual: ellos ingenieros\n",
            "--------------------\n",
            "Example 233:\n",
            "Predicted: novio mío loco\n",
            "Actual: novio mío loco\n",
            "--------------------\n",
            "Example 234:\n",
            "Predicted: primo tuyo médico\n",
            "Actual: primo tuyo médico\n",
            "--------------------\n",
            "Example 235:\n",
            "Predicted: mamá mía enojada\n",
            "Actual: mamá mía enojada\n",
            "--------------------\n",
            "Example 236:\n",
            "Predicted: hermano mujer ellas\n",
            "Actual: hermano mujer ellas\n",
            "--------------------\n",
            "Example 237:\n",
            "Predicted: hermano mujer tuya café gustar no\n",
            "Actual: hermano mujer tuya café gustar no\n",
            "--------------------\n",
            "Example 238:\n",
            "Predicted: novio mío lsm aprender querer\n",
            "Actual: novio mío lsm aprender querer\n",
            "--------------------\n",
            "Example 239:\n",
            "Predicted: yo hombre\n",
            "Actual: yo hombre\n",
            "--------------------\n",
            "Example 240:\n",
            "Predicted: auto cl+cl+cl míos\n",
            "Actual: amigo mujer ellas mías\n",
            "--------------------\n",
            "Example 241:\n",
            "Predicted: hermano mujer mía pescado comer\n",
            "Actual: hermano mujer mía pescado comer\n",
            "--------------------\n",
            "Example 242:\n",
            "Predicted: perro suyo\n",
            "Actual: perro suyo\n",
            "--------------------\n",
            "Example 243:\n",
            "Predicted: tío mujer nuestra\n",
            "Actual: tío mujer nuestra\n",
            "--------------------\n",
            "Example 244:\n",
            "Predicted: abuelo mujer mía\n",
            "Actual: abuelo mujer mía\n",
            "--------------------\n",
            "Example 245:\n",
            "Predicted: tío mujer mía lsm aprender querer\n",
            "Actual: tío mujer mía lsm aprender querer\n",
            "--------------------\n",
            "Example 246:\n",
            "Predicted: niño ellos jóvenes\n",
            "Actual: niño ellos jovenes así\n",
            "--------------------\n",
            "Example 247:\n",
            "Predicted: amigo mujer mía lsm entender no\n",
            "Actual: amigo mujer mía lsm entender no\n",
            "--------------------\n",
            "Example 248:\n",
            "Predicted: no, papá mío oyente\n",
            "Actual: no, papá mío oyente\n",
            "--------------------\n",
            "Example 249:\n",
            "Predicted: próxima semana amigo mío universidad ir\n",
            "Actual: próxima semana amigo mío universidad ir\n",
            "--------------------\n",
            "Example 250:\n",
            "Predicted: ella chocolate gustar\n",
            "Actual: él chocolate gustar\n",
            "--------------------\n",
            "Example 251:\n",
            "Predicted: ellas español aprender querer\n",
            "Actual: ellas español aprender querer\n",
            "--------------------\n",
            "Example 252:\n",
            "Predicted: yo lsm entender no\n",
            "Actual: yo lsm entender\n",
            "--------------------\n",
            "Example 253:\n",
            "Predicted: hombre ellos\n",
            "Actual: hombre ellos\n",
            "--------------------\n",
            "Example 254:\n",
            "Predicted: eso yo hacer poder no\n",
            "Actual: eso yo hacer poder no\n",
            "--------------------\n",
            "Example 255:\n",
            "Predicted: comida servida\n",
            "Actual: comida servida\n",
            "--------------------\n",
            "Example 256:\n",
            "Predicted: esposo algunos\n",
            "Actual: esposo algunos\n",
            "--------------------\n",
            "Example 257:\n",
            "Predicted: novio mío triste\n",
            "Actual: novio mío triste\n",
            "--------------------\n",
            "Example 258:\n",
            "Predicted: primo mujer mía embarazada\n",
            "Actual: primo mujer mía embarazada\n",
            "--------------------\n",
            "Example 259:\n",
            "Predicted: ¿tío tuyo oyente?\n",
            "Actual: ¿tío tuyo oyente?\n",
            "--------------------\n",
            "Example 260:\n",
            "Predicted: niño ellos\n",
            "Actual: hombre ellos\n",
            "--------------------\n",
            "Example 261:\n",
            "Predicted: nosotros descansar querer\n",
            "Actual: nosotros descansar querer\n",
            "--------------------\n",
            "Example 262:\n",
            "Predicted: niño mujer ellas bien\n",
            "Actual: niño mujer ellas bien\n",
            "--------------------\n",
            "Example 263:\n",
            "Predicted: cacerola ahí abuelo mujer mía arroz hacer\n",
            "Actual: abuelo mujer mía cacerola arroz cocinar\n",
            "--------------------\n",
            "Example 264:\n",
            "Predicted: pasado novio mujer mía biblioteca ir\n",
            "Actual: pasado novio mujer mía biblioteca ir\n",
            "--------------------\n",
            "Example 265:\n",
            "Predicted: hermano mujer mía sorda\n",
            "Actual: hermano mujer mía sorda\n",
            "--------------------\n",
            "Example 266:\n",
            "Predicted: tío mujer mía distraída así\n",
            "Actual: tío mujer mía distraída así\n",
            "--------------------\n",
            "Example 267:\n",
            "Predicted: clima frío\n",
            "Actual: clima frío\n",
            "--------------------\n",
            "Example 268:\n",
            "Predicted: ellos confundidos\n",
            "Actual: ellos confundidos\n",
            "--------------------\n",
            "Example 269:\n",
            "Predicted: ella loca\n",
            "Actual: ella loca\n",
            "--------------------\n",
            "Example 270:\n",
            "Predicted: ellas lsm aprender\n",
            "Actual: ellas lsm aprender\n",
            "--------------------\n",
            "Example 271:\n",
            "Predicted: tío mujer mía abogada\n",
            "Actual: tío mujer mía abogada\n",
            "--------------------\n",
            "Example 272:\n",
            "Predicted: ellas arquitectas\n",
            "Actual: ellas arquitectas\n",
            "--------------------\n",
            "Example 273:\n",
            "Predicted: mujer muchas\n",
            "Actual: mujer muchas\n",
            "--------------------\n",
            "Example 274:\n",
            "Predicted: tú ser\n",
            "Actual: tú ser\n",
            "--------------------\n",
            "Example 275:\n",
            "Predicted: ayer yo huevos comer\n",
            "Actual: ayer yo huevos comer\n",
            "--------------------\n",
            "Example 276:\n",
            "Predicted: ayer ellos (as) (ustedes) libro leer\n",
            "Actual: ayer ellos (as) libro leer\n",
            "--------------------\n",
            "Example 277:\n",
            "Predicted: gato tuyo\n",
            "Actual: gato tuyo\n",
            "--------------------\n",
            "Example 278:\n",
            "Predicted: tú loco\n",
            "Actual: tú loco\n",
            "--------------------\n",
            "Example 279:\n",
            "Predicted: hermano mío triste\n",
            "Actual: hermano mío triste\n",
            "--------------------\n",
            "Example 280:\n",
            "Predicted: ayer primo mujer mío libro leer\n",
            "Actual: ayer primo mujer mía libro leer\n",
            "--------------------\n",
            "Example 281:\n",
            "Predicted: tú leer gustar no\n",
            "Actual: tú leer gustar no\n",
            "--------------------\n",
            "Example 282:\n",
            "Predicted: ustedes miedosos así\n",
            "Actual: ustedes miedosos así\n",
            "--------------------\n",
            "Example 283:\n",
            "Predicted: semana pasada él hacer eso\n",
            "Actual: semana pasada éleso hacer\n",
            "--------------------\n",
            "Example 284:\n",
            "Predicted: manzana roja\n",
            "Actual: manzana roja\n",
            "--------------------\n",
            "Example 285:\n",
            "Predicted: pista ahí él (ella) correr\n",
            "Actual: pista ahí él (ella) correr querer\n",
            "--------------------\n",
            "Example 286:\n",
            "Predicted: tú sonreír gustar\n",
            "Actual: tú sonreír gustar\n",
            "--------------------\n",
            "Example 287:\n",
            "Predicted: nosotros\n",
            "Actual: nosotros\n",
            "--------------------\n",
            "Example 288:\n",
            "Predicted: suegro mujer ellas\n",
            "Actual: suegro mujer ellas\n",
            "--------------------\n",
            "Example 289:\n",
            "Predicted: niño mujer ellas enojonas así\n",
            "Actual: niño mujer ellas enojonas así\n",
            "--------------------\n",
            "Example 290:\n",
            "Predicted: ellos caminar gustar no\n",
            "Actual: ellos caminar gustar no\n",
            "--------------------\n",
            "Example 291:\n",
            "Predicted: ellos café gustar no\n",
            "Actual: ustedes café gustar no\n",
            "--------------------\n",
            "Example 292:\n",
            "Predicted: día caluroso\n",
            "Actual: día caluroso\n",
            "--------------------\n",
            "Example 293:\n",
            "Predicted: lunes a viernes nosotros trabajar\n",
            "Actual: lunes a viernes nosotros trabajar\n",
            "--------------------\n",
            "Example 294:\n",
            "Predicted: mujer enojada\n",
            "Actual: mujer enojada\n",
            "--------------------\n",
            "Example 295:\n",
            "Predicted: novio mujer mía masomenos\n",
            "Actual: novio mujer mía masomenos\n",
            "--------------------\n",
            "Example 296:\n",
            "Predicted: ella cerveza beber\n",
            "Actual: ella cerveza beber\n",
            "--------------------\n",
            "Example 297:\n",
            "Predicted: niño mujer ellas estudiar\n",
            "Actual: niño mujer ellas estudiar\n",
            "--------------------\n",
            "Example 298:\n",
            "Predicted: cafetería ahí tío tuyo café tomar\n",
            "Actual: cafetería tío tuyo café beber\n",
            "--------------------\n",
            "Example 299:\n",
            "Predicted: tío tuyo chocolate gustar\n",
            "Actual: tío tuyo chocolate gustar\n",
            "--------------------\n",
            "Example 300:\n",
            "Predicted: biblioteca ahí sobrino mujer mía estudiar\n",
            "Actual: biblioteca ahí sobrino mujer estudiar\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_translations_to_txt(predicted_translations, actual_translations, filename=\"/content/drive/MyDrive/doctorado/paper_scientificdata/translationsM2.txt\", delimiter=\"\\t\"):\n",
        "  \"\"\"Saves predicted and actual translations to a text file.\n",
        "\n",
        "  Args:\n",
        "    predicted_translations: A list or array of predicted translations.\n",
        "    actual_translations: A list or array of actual translations.\n",
        "    filename: The name of the file to save the translations to.\n",
        "    delimiter: The delimiter to use between predicted and actual translations. Defaults to a tab.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for predicted, actual in zip(predicted_translations, actual_translations):\n",
        "      f.write(predicted + delimiter + actual + \"\\n\")\n",
        "  print(f\"Translations saved to {filename}\")\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'predicted_translations' and 'actual_translations' are your lists of translations\n",
        "save_translations_to_txt(predicted_translations, actual_translations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IsxXPcLmgox",
        "outputId": "b4b5ae45-7ad7-4e25-cff7-ddf9880092a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translations saved to /content/drive/MyDrive/doctorado/paper_scientificdata/translationsM2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text2text-generation\", model=\"VaniLara/esp-to-lsm-barto-model\")"
      ],
      "metadata": {
        "id": "4y2bIpKR8TNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"me gusta el suéter rosa\"\n",
        "tr=pipe(text)\n",
        "tr"
      ],
      "metadata": {
        "id": "hGUrL_pn8kBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"VaniLara/esp-to-lsm-barto-model\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"VaniLara/esp-to-lsm-barto-model\")"
      ],
      "metadata": {
        "id": "9IUiaKGO50vJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d8b0dd5fab34640976b6ba1985138fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_635ccc59cb884d92838878850caf1144",
              "IPY_MODEL_a6fe772e5bd24b06bdd466e0fe8ec055",
              "IPY_MODEL_770a9a7d21c9422cb2874200ddc5c595",
              "IPY_MODEL_d67e9fc7ade346afa00a75d00b02c41b",
              "IPY_MODEL_103169bb646945b68f8d7d6f6d9744e8"
            ],
            "layout": "IPY_MODEL_bc95a85a48e940e0a24b9e6f1bccb7ab"
          }
        },
        "635ccc59cb884d92838878850caf1144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48e518d4a2cf4d1f8d021d29a5ec3fe5",
            "placeholder": "​",
            "style": "IPY_MODEL_72064ae2af364427be9da97a78377072",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a6fe772e5bd24b06bdd466e0fe8ec055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ee9727b985a44caf8eec89f98878d16f",
            "placeholder": "​",
            "style": "IPY_MODEL_d1520b4fdf724c3b8b1e172e7225b880",
            "value": ""
          }
        },
        "770a9a7d21c9422cb2874200ddc5c595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_370bff4a7508448aadb1f2b14e5a1a16",
            "style": "IPY_MODEL_0a1bc785b7424d71a4a4a8096c1a1961",
            "value": true
          }
        },
        "d67e9fc7ade346afa00a75d00b02c41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_158fd57097fd497497d5b7a5f3885f69",
            "style": "IPY_MODEL_4cbfd957f8104ebaaa96688fd638099b",
            "tooltip": ""
          }
        },
        "103169bb646945b68f8d7d6f6d9744e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c6fcc8b0a004337b7a9038a7ede2a3b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c0cb241c8814ac084199253bc7c43a4",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "bc95a85a48e940e0a24b9e6f1bccb7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "48e518d4a2cf4d1f8d021d29a5ec3fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72064ae2af364427be9da97a78377072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9727b985a44caf8eec89f98878d16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1520b4fdf724c3b8b1e172e7225b880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "370bff4a7508448aadb1f2b14e5a1a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1bc785b7424d71a4a4a8096c1a1961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "158fd57097fd497497d5b7a5f3885f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbfd957f8104ebaaa96688fd638099b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0c6fcc8b0a004337b7a9038a7ede2a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0cb241c8814ac084199253bc7c43a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a74dd3cbb14fa3afa7dc2527114aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ad073f22686411e9e541a33fc938257",
              "IPY_MODEL_897a8362c2334501b5ee98d03773a75e",
              "IPY_MODEL_8296ed2754d34574b9919e50264290db"
            ],
            "layout": "IPY_MODEL_500d63950d02476c815d3ab274f32fbb"
          }
        },
        "7ad073f22686411e9e541a33fc938257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1fbaca5b0646989b4106dd3d9bb1d1",
            "placeholder": "​",
            "style": "IPY_MODEL_37571fdcdc70462db11ad3c0aa96d0ad",
            "value": "Map: 100%"
          }
        },
        "897a8362c2334501b5ee98d03773a75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3195d2b77743a9a4ca4d55b9dc540a",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcd16a0f508b497584f8c1e3d568a59a",
            "value": 300
          }
        },
        "8296ed2754d34574b9919e50264290db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cfca797c05343e3904420bc36393bca",
            "placeholder": "​",
            "style": "IPY_MODEL_0bdd0e4587d7461fa397b4f9b1cc03de",
            "value": " 300/300 [00:00&lt;00:00, 4407.85 examples/s]"
          }
        },
        "500d63950d02476c815d3ab274f32fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1fbaca5b0646989b4106dd3d9bb1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37571fdcdc70462db11ad3c0aa96d0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c3195d2b77743a9a4ca4d55b9dc540a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd16a0f508b497584f8c1e3d568a59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cfca797c05343e3904420bc36393bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdd0e4587d7461fa397b4f9b1cc03de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5551ca10a2484f0084dc82ad5975e62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1c72eafcbcb4c9ea8e0924cca78b55a",
              "IPY_MODEL_d5ce4392807747deae3d5c5c7cb8f39f",
              "IPY_MODEL_e0c3ddd59ad745089702ffe4f42cc804"
            ],
            "layout": "IPY_MODEL_c958e8fd0f5b48f7a741da9a56c63c92"
          }
        },
        "d1c72eafcbcb4c9ea8e0924cca78b55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_453376ae9924425a9106678b79d13499",
            "placeholder": "​",
            "style": "IPY_MODEL_10a4ecb669d649b8ad60cfaa56480a2d",
            "value": "Map: 100%"
          }
        },
        "d5ce4392807747deae3d5c5c7cb8f39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71b37807b8948f2be57cbc71f36cf8f",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63a170db561440138f7116b0b4e811bb",
            "value": 300
          }
        },
        "e0c3ddd59ad745089702ffe4f42cc804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b2606e15f44d8aa0b43c7abfecaa11",
            "placeholder": "​",
            "style": "IPY_MODEL_2c59660425c5417597ede088d5c79696",
            "value": " 300/300 [00:00&lt;00:00, 4398.62 examples/s]"
          }
        },
        "c958e8fd0f5b48f7a741da9a56c63c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453376ae9924425a9106678b79d13499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a4ecb669d649b8ad60cfaa56480a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d71b37807b8948f2be57cbc71f36cf8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a170db561440138f7116b0b4e811bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6b2606e15f44d8aa0b43c7abfecaa11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c59660425c5417597ede088d5c79696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91bddb341ddd431982625ffc11063b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c72b2309460b4458a9d0ce6f3c248cdf",
              "IPY_MODEL_cc464f5f15424562b9485b734df0fc3e",
              "IPY_MODEL_c97df095857a43768603bdb77fd05c28"
            ],
            "layout": "IPY_MODEL_aff035ed7c834cabb37fc853bd91c81f"
          }
        },
        "c72b2309460b4458a9d0ce6f3c248cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dbac482437a4fa5a57518936b1b102e",
            "placeholder": "​",
            "style": "IPY_MODEL_b1507b8d206c498ab2b2bf855a7cbd8f",
            "value": "Upload file pytorch_model.bin: 100%"
          }
        },
        "cc464f5f15424562b9485b734df0fc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3faa87104f468996ba41e037872295",
            "max": 557968602,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41d1dd8a0d18496bb7c436084afccc22",
            "value": 557968602
          }
        },
        "c97df095857a43768603bdb77fd05c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60e12d3b34c4e38af813abf52e31d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_f6606743fc484ce5a1c04c8f0cbab004",
            "value": " 532M/532M [00:36&lt;00:00, 22.4MB/s]"
          }
        },
        "aff035ed7c834cabb37fc853bd91c81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dbac482437a4fa5a57518936b1b102e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1507b8d206c498ab2b2bf855a7cbd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3faa87104f468996ba41e037872295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d1dd8a0d18496bb7c436084afccc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a60e12d3b34c4e38af813abf52e31d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6606743fc484ce5a1c04c8f0cbab004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7da10d5f4ba24231b227b115f6ca3377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5c099c82caf4cec9a8ec3425c9448c1",
              "IPY_MODEL_62812dbff4aa4109802328184edaedd8",
              "IPY_MODEL_8c4da1141bcc4a75847ed280ee60f9fd"
            ],
            "layout": "IPY_MODEL_042412ff12d14b948a6e52ff7b4222ef"
          }
        },
        "c5c099c82caf4cec9a8ec3425c9448c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f483b4d8ed45d191430512ab136c40",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a28397534b4228adcbe8b65b018db5",
            "value": "Upload file runs/Oct24_16-26-11_0b0e597821aa/events.out.tfevents.1729787192.0b0e597821aa.8338.5: 100%"
          }
        },
        "62812dbff4aa4109802328184edaedd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd60746bbbcd4ebe9999a11d4459bfb9",
            "max": 24207,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68c7681eeb9a49a79514c3872a9145dc",
            "value": 24207
          }
        },
        "8c4da1141bcc4a75847ed280ee60f9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41fe32e22414b84bb6bb745d7d75d31",
            "placeholder": "​",
            "style": "IPY_MODEL_3e853e0a7b034f378e286f5371b7a1ad",
            "value": " 23.6k/23.6k [00:36&lt;00:00, 444kB/s]"
          }
        },
        "042412ff12d14b948a6e52ff7b4222ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f483b4d8ed45d191430512ab136c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a28397534b4228adcbe8b65b018db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd60746bbbcd4ebe9999a11d4459bfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c7681eeb9a49a79514c3872a9145dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c41fe32e22414b84bb6bb745d7d75d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e853e0a7b034f378e286f5371b7a1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217c4ba1053a42cf8f54958535cc873c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a990451eea064ef29be2c5024079fe20",
              "IPY_MODEL_3957c71565674a409524597e464a1c6a",
              "IPY_MODEL_22d576856e5e4c3d8e5067dd6e033416"
            ],
            "layout": "IPY_MODEL_8683985822ec44079ce3d0a636cfecab"
          }
        },
        "a990451eea064ef29be2c5024079fe20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_511a01a81c894dd59ea02772f38591bd",
            "placeholder": "​",
            "style": "IPY_MODEL_c3f048367cc14515906e892fdc119163",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3957c71565674a409524597e464a1c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687ac425500345899ac931625a8b079c",
            "max": 557968602,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7a0464c7be844a2b7aab9ce2ff37af8",
            "value": 557968602
          }
        },
        "22d576856e5e4c3d8e5067dd6e033416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bba3d8b73384cbaa10b8ccc9c7a765d",
            "placeholder": "​",
            "style": "IPY_MODEL_50f06748a5de4bc8b263706bcb8e6f87",
            "value": " 558M/558M [00:24&lt;00:00, 24.1MB/s]"
          }
        },
        "8683985822ec44079ce3d0a636cfecab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511a01a81c894dd59ea02772f38591bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f048367cc14515906e892fdc119163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "687ac425500345899ac931625a8b079c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a0464c7be844a2b7aab9ce2ff37af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bba3d8b73384cbaa10b8ccc9c7a765d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f06748a5de4bc8b263706bcb8e6f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}